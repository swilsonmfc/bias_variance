{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FeatureSelection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN2OPx6+BRNkUunWtz3QnTG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swilsonmfc/bias_variance/blob/main/FeatureSelection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPY4gSsOyQ6t"
      },
      "source": [
        "# Feature Selection\n",
        "\n",
        "![](https://benthamopen.com/contents/figures/TOBIOIJ/TOBIOIJ-11-117_F3.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGcnDLQdyVVX"
      },
      "source": [
        "# Install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIuCBfzzyesr",
        "outputId": "96dca501-6fb1-44e7-9b0b-32bad7d6009b"
      },
      "source": [
        "!pip install feature_engine"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: feature_engine in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied: pandas>=1.0.3 in /usr/local/lib/python3.7/dist-packages (from feature_engine) (1.1.5)\n",
            "Requirement already satisfied: statsmodels>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from feature_engine) (0.12.2)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.7/dist-packages (from feature_engine) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from feature_engine) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.7/dist-packages (from feature_engine) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.3->feature_engine) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.3->feature_engine) (2018.9)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.7/dist-packages (from statsmodels>=0.11.1->feature_engine) (0.5.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.2->feature_engine) (1.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.0.3->feature_engine) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFDJ8bf-yVTK"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ui1ofikYyXm7"
      },
      "source": [
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pandas_profiling\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
        "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.feature_selection import SelectPercentile\n",
        "from sklearn.feature_selection import f_regression\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.feature_selection import RFE\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from feature_engine.encoding import OneHotEncoder"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-C5Ur_xl2xL5"
      },
      "source": [
        "pd.set_option('display.max_rows', 200)\n",
        "pd.set_option('display.max_columns', 200)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwgZXeOMzNlb"
      },
      "source": [
        "# Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "s8q5L9JkzOzB",
        "outputId": "b6ceffeb-cc22-4732-ce00-acb5659f1b99"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c8dfe545-938b-4f83-b89e-edaa6beb0b3b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c8dfe545-938b-4f83-b89e-edaa6beb0b3b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OafTPfx6yVQ4"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZgd9vGWzbHo",
        "outputId": "0b968c7f-e8b1-4fa0-fc92-b2a97101669f"
      },
      "source": [
        "!kaggle competitions download -c allstate-claims-severity"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "test.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "test.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "train.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "sample_submission.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "train.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "sample_submission.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7q1Ipes9yTdx",
        "outputId": "954f7180-adb4-4f4e-d605-3974e0caf453"
      },
      "source": [
        "!unzip train.csv.zip "
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  train.csv.zip\n",
            "replace train.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBXliAFIzqhG",
        "outputId": "1a838f40-172c-48e9-8099-2e530d2e8ac5"
      },
      "source": [
        "df = pd.read_csv('train.csv', warn_bad_lines=False, error_bad_lines=False)\n",
        "df.shape"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(188319, 132)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c_szS211jm4"
      },
      "source": [
        "# EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "T2B8Msmk0E2g",
        "outputId": "c40eef45-0105-4f0a-9272-3742b2ec32d4"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>cat1</th>\n",
              "      <th>cat2</th>\n",
              "      <th>cat3</th>\n",
              "      <th>cat4</th>\n",
              "      <th>cat5</th>\n",
              "      <th>cat6</th>\n",
              "      <th>cat7</th>\n",
              "      <th>cat8</th>\n",
              "      <th>cat9</th>\n",
              "      <th>cat10</th>\n",
              "      <th>cat11</th>\n",
              "      <th>cat12</th>\n",
              "      <th>cat13</th>\n",
              "      <th>cat14</th>\n",
              "      <th>cat15</th>\n",
              "      <th>cat16</th>\n",
              "      <th>cat17</th>\n",
              "      <th>cat18</th>\n",
              "      <th>cat19</th>\n",
              "      <th>cat20</th>\n",
              "      <th>cat21</th>\n",
              "      <th>cat22</th>\n",
              "      <th>cat23</th>\n",
              "      <th>cat24</th>\n",
              "      <th>cat25</th>\n",
              "      <th>cat26</th>\n",
              "      <th>cat27</th>\n",
              "      <th>cat28</th>\n",
              "      <th>cat29</th>\n",
              "      <th>cat30</th>\n",
              "      <th>cat31</th>\n",
              "      <th>cat32</th>\n",
              "      <th>cat33</th>\n",
              "      <th>cat34</th>\n",
              "      <th>cat35</th>\n",
              "      <th>cat36</th>\n",
              "      <th>cat37</th>\n",
              "      <th>cat38</th>\n",
              "      <th>cat39</th>\n",
              "      <th>cat40</th>\n",
              "      <th>cat41</th>\n",
              "      <th>cat42</th>\n",
              "      <th>cat43</th>\n",
              "      <th>cat44</th>\n",
              "      <th>cat45</th>\n",
              "      <th>cat46</th>\n",
              "      <th>cat47</th>\n",
              "      <th>cat48</th>\n",
              "      <th>cat49</th>\n",
              "      <th>cat50</th>\n",
              "      <th>cat51</th>\n",
              "      <th>cat52</th>\n",
              "      <th>cat53</th>\n",
              "      <th>cat54</th>\n",
              "      <th>cat55</th>\n",
              "      <th>cat56</th>\n",
              "      <th>cat57</th>\n",
              "      <th>cat58</th>\n",
              "      <th>cat59</th>\n",
              "      <th>cat60</th>\n",
              "      <th>cat61</th>\n",
              "      <th>cat62</th>\n",
              "      <th>cat63</th>\n",
              "      <th>cat64</th>\n",
              "      <th>cat65</th>\n",
              "      <th>cat66</th>\n",
              "      <th>cat67</th>\n",
              "      <th>cat68</th>\n",
              "      <th>cat69</th>\n",
              "      <th>cat70</th>\n",
              "      <th>cat71</th>\n",
              "      <th>cat72</th>\n",
              "      <th>cat73</th>\n",
              "      <th>cat74</th>\n",
              "      <th>cat75</th>\n",
              "      <th>cat76</th>\n",
              "      <th>cat77</th>\n",
              "      <th>cat78</th>\n",
              "      <th>cat79</th>\n",
              "      <th>cat80</th>\n",
              "      <th>cat81</th>\n",
              "      <th>cat82</th>\n",
              "      <th>cat83</th>\n",
              "      <th>cat84</th>\n",
              "      <th>cat85</th>\n",
              "      <th>cat86</th>\n",
              "      <th>cat87</th>\n",
              "      <th>cat88</th>\n",
              "      <th>cat89</th>\n",
              "      <th>cat90</th>\n",
              "      <th>cat91</th>\n",
              "      <th>cat92</th>\n",
              "      <th>cat93</th>\n",
              "      <th>cat94</th>\n",
              "      <th>cat95</th>\n",
              "      <th>cat96</th>\n",
              "      <th>cat97</th>\n",
              "      <th>cat98</th>\n",
              "      <th>cat99</th>\n",
              "      <th>cat100</th>\n",
              "      <th>cat101</th>\n",
              "      <th>cat102</th>\n",
              "      <th>cat103</th>\n",
              "      <th>cat104</th>\n",
              "      <th>cat105</th>\n",
              "      <th>cat106</th>\n",
              "      <th>cat107</th>\n",
              "      <th>cat108</th>\n",
              "      <th>cat109</th>\n",
              "      <th>cat110</th>\n",
              "      <th>cat111</th>\n",
              "      <th>cat112</th>\n",
              "      <th>cat113</th>\n",
              "      <th>cat114</th>\n",
              "      <th>cat115</th>\n",
              "      <th>cat116</th>\n",
              "      <th>cont1</th>\n",
              "      <th>cont2</th>\n",
              "      <th>cont3</th>\n",
              "      <th>cont4</th>\n",
              "      <th>cont5</th>\n",
              "      <th>cont6</th>\n",
              "      <th>cont7</th>\n",
              "      <th>cont8</th>\n",
              "      <th>cont9</th>\n",
              "      <th>cont10</th>\n",
              "      <th>cont11</th>\n",
              "      <th>cont12</th>\n",
              "      <th>cont13</th>\n",
              "      <th>cont14</th>\n",
              "      <th>loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>A</td>\n",
              "      <td>B</td>\n",
              "      <td>A</td>\n",
              "      <td>B</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>B</td>\n",
              "      <td>A</td>\n",
              "      <td>B</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>B</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>B</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>B</td>\n",
              "      <td>B</td>\n",
              "      <td>D</td>\n",
              "      <td>D</td>\n",
              "      <td>B</td>\n",
              "      <td>D</td>\n",
              "      <td>C</td>\n",
              "      <td>B</td>\n",
              "      <td>D</td>\n",
              "      <td>B</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>B</td>\n",
              "      <td>C</td>\n",
              "      <td>E</td>\n",
              "      <td>A</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>B</td>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>I</td>\n",
              "      <td>E</td>\n",
              "      <td>G</td>\n",
              "      <td>J</td>\n",
              "      <td>G</td>\n",
              "      <td>BU</td>\n",
              "      <td>BC</td>\n",
              "      <td>C</td>\n",
              "      <td>AS</td>\n",
              "      <td>S</td>\n",
              "      <td>A</td>\n",
              "      <td>O</td>\n",
              "      <td>LB</td>\n",
              "      <td>0.726300</td>\n",
              "      <td>0.245921</td>\n",
              "      <td>0.187583</td>\n",
              "      <td>0.789639</td>\n",
              "      <td>0.310061</td>\n",
              "      <td>0.718367</td>\n",
              "      <td>0.335060</td>\n",
              "      <td>0.30260</td>\n",
              "      <td>0.67135</td>\n",
              "      <td>0.83510</td>\n",
              "      <td>0.569745</td>\n",
              "      <td>0.594646</td>\n",
              "      <td>0.822493</td>\n",
              "      <td>0.714843</td>\n",
              "      <td>2213.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.0</td>\n",
              "      <td>A</td>\n",
              "      <td>B</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>B</td>\n",
              "      <td>B</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>B</td>\n",
              "      <td>B</td>\n",
              "      <td>D</td>\n",
              "      <td>D</td>\n",
              "      <td>A</td>\n",
              "      <td>B</td>\n",
              "      <td>C</td>\n",
              "      <td>B</td>\n",
              "      <td>D</td>\n",
              "      <td>B</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>D</td>\n",
              "      <td>C</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>D</td>\n",
              "      <td>T</td>\n",
              "      <td>L</td>\n",
              "      <td>F</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>I</td>\n",
              "      <td>K</td>\n",
              "      <td>K</td>\n",
              "      <td>BI</td>\n",
              "      <td>CQ</td>\n",
              "      <td>A</td>\n",
              "      <td>AV</td>\n",
              "      <td>BM</td>\n",
              "      <td>A</td>\n",
              "      <td>O</td>\n",
              "      <td>DP</td>\n",
              "      <td>0.330514</td>\n",
              "      <td>0.737068</td>\n",
              "      <td>0.592681</td>\n",
              "      <td>0.614134</td>\n",
              "      <td>0.885834</td>\n",
              "      <td>0.438917</td>\n",
              "      <td>0.436585</td>\n",
              "      <td>0.60087</td>\n",
              "      <td>0.35127</td>\n",
              "      <td>0.43919</td>\n",
              "      <td>0.338312</td>\n",
              "      <td>0.366307</td>\n",
              "      <td>0.611431</td>\n",
              "      <td>0.304496</td>\n",
              "      <td>1283.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.0</td>\n",
              "      <td>A</td>\n",
              "      <td>B</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>B</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>B</td>\n",
              "      <td>B</td>\n",
              "      <td>B</td>\n",
              "      <td>B</td>\n",
              "      <td>B</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>B</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>B</td>\n",
              "      <td>B</td>\n",
              "      <td>B</td>\n",
              "      <td>D</td>\n",
              "      <td>B</td>\n",
              "      <td>D</td>\n",
              "      <td>C</td>\n",
              "      <td>B</td>\n",
              "      <td>B</td>\n",
              "      <td>B</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>D</td>\n",
              "      <td>C</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>L</td>\n",
              "      <td>O</td>\n",
              "      <td>A</td>\n",
              "      <td>B</td>\n",
              "      <td>E</td>\n",
              "      <td>F</td>\n",
              "      <td>H</td>\n",
              "      <td>F</td>\n",
              "      <td>A</td>\n",
              "      <td>AB</td>\n",
              "      <td>DK</td>\n",
              "      <td>A</td>\n",
              "      <td>C</td>\n",
              "      <td>AF</td>\n",
              "      <td>A</td>\n",
              "      <td>I</td>\n",
              "      <td>GK</td>\n",
              "      <td>0.261841</td>\n",
              "      <td>0.358319</td>\n",
              "      <td>0.484196</td>\n",
              "      <td>0.236924</td>\n",
              "      <td>0.397069</td>\n",
              "      <td>0.289648</td>\n",
              "      <td>0.315545</td>\n",
              "      <td>0.27320</td>\n",
              "      <td>0.26076</td>\n",
              "      <td>0.32446</td>\n",
              "      <td>0.381398</td>\n",
              "      <td>0.373424</td>\n",
              "      <td>0.195709</td>\n",
              "      <td>0.774425</td>\n",
              "      <td>3005.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10.0</td>\n",
              "      <td>B</td>\n",
              "      <td>B</td>\n",
              "      <td>A</td>\n",
              "      <td>B</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>B</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>B</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>B</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>B</td>\n",
              "      <td>B</td>\n",
              "      <td>D</td>\n",
              "      <td>D</td>\n",
              "      <td>D</td>\n",
              "      <td>B</td>\n",
              "      <td>C</td>\n",
              "      <td>B</td>\n",
              "      <td>D</td>\n",
              "      <td>B</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>D</td>\n",
              "      <td>C</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>D</td>\n",
              "      <td>T</td>\n",
              "      <td>I</td>\n",
              "      <td>D</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>I</td>\n",
              "      <td>K</td>\n",
              "      <td>K</td>\n",
              "      <td>BI</td>\n",
              "      <td>CS</td>\n",
              "      <td>C</td>\n",
              "      <td>N</td>\n",
              "      <td>AE</td>\n",
              "      <td>A</td>\n",
              "      <td>O</td>\n",
              "      <td>DJ</td>\n",
              "      <td>0.321594</td>\n",
              "      <td>0.555782</td>\n",
              "      <td>0.527991</td>\n",
              "      <td>0.373816</td>\n",
              "      <td>0.422268</td>\n",
              "      <td>0.440945</td>\n",
              "      <td>0.391128</td>\n",
              "      <td>0.31796</td>\n",
              "      <td>0.32128</td>\n",
              "      <td>0.44467</td>\n",
              "      <td>0.327915</td>\n",
              "      <td>0.321570</td>\n",
              "      <td>0.605077</td>\n",
              "      <td>0.602642</td>\n",
              "      <td>939.85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11.0</td>\n",
              "      <td>A</td>\n",
              "      <td>B</td>\n",
              "      <td>A</td>\n",
              "      <td>B</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>B</td>\n",
              "      <td>B</td>\n",
              "      <td>A</td>\n",
              "      <td>B</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>B</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>B</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>B</td>\n",
              "      <td>D</td>\n",
              "      <td>B</td>\n",
              "      <td>D</td>\n",
              "      <td>B</td>\n",
              "      <td>B</td>\n",
              "      <td>C</td>\n",
              "      <td>B</td>\n",
              "      <td>B</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>B</td>\n",
              "      <td>H</td>\n",
              "      <td>D</td>\n",
              "      <td>B</td>\n",
              "      <td>D</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>A</td>\n",
              "      <td>P</td>\n",
              "      <td>F</td>\n",
              "      <td>J</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>D</td>\n",
              "      <td>E</td>\n",
              "      <td>K</td>\n",
              "      <td>G</td>\n",
              "      <td>B</td>\n",
              "      <td>H</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>Y</td>\n",
              "      <td>BM</td>\n",
              "      <td>A</td>\n",
              "      <td>K</td>\n",
              "      <td>CK</td>\n",
              "      <td>0.273204</td>\n",
              "      <td>0.159990</td>\n",
              "      <td>0.527991</td>\n",
              "      <td>0.473202</td>\n",
              "      <td>0.704268</td>\n",
              "      <td>0.178193</td>\n",
              "      <td>0.247408</td>\n",
              "      <td>0.24564</td>\n",
              "      <td>0.22089</td>\n",
              "      <td>0.21230</td>\n",
              "      <td>0.204687</td>\n",
              "      <td>0.202213</td>\n",
              "      <td>0.246011</td>\n",
              "      <td>0.432606</td>\n",
              "      <td>2763.85</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9 cat10 cat11 cat12 cat13  \\\n",
              "0   1.0    A    B    A    B    A    A    A    A    B     A     B     A     A   \n",
              "1   2.0    A    B    A    A    A    A    A    A    B     B     A     A     A   \n",
              "2   5.0    A    B    A    A    B    A    A    A    B     B     B     B     B   \n",
              "3  10.0    B    B    A    B    A    A    A    A    B     A     A     A     A   \n",
              "4  11.0    A    B    A    B    A    A    A    A    B     B     A     B     A   \n",
              "\n",
              "  cat14 cat15 cat16 cat17 cat18 cat19 cat20 cat21 cat22 cat23 cat24 cat25  \\\n",
              "0     A     A     A     A     A     A     A     A     A     B     A     A   \n",
              "1     A     A     A     A     A     A     A     A     A     A     A     A   \n",
              "2     A     A     A     A     A     A     A     A     A     A     A     A   \n",
              "3     A     A     A     A     A     A     A     A     A     B     A     A   \n",
              "4     A     A     A     A     A     A     A     A     A     B     A     A   \n",
              "\n",
              "  cat26 cat27 cat28 cat29 cat30 cat31 cat32 cat33 cat34 cat35 cat36 cat37  \\\n",
              "0     A     A     A     A     A     A     A     A     A     A     A     A   \n",
              "1     A     A     A     A     A     A     A     A     A     A     A     A   \n",
              "2     A     A     A     A     A     A     A     A     A     A     B     A   \n",
              "3     A     A     A     A     A     A     A     A     A     A     A     A   \n",
              "4     A     A     A     A     A     A     A     A     A     A     A     A   \n",
              "\n",
              "  cat38 cat39 cat40 cat41 cat42 cat43 cat44 cat45 cat46 cat47 cat48 cat49  \\\n",
              "0     A     A     A     A     A     A     A     A     A     A     A     A   \n",
              "1     A     A     A     A     A     A     A     A     A     A     A     A   \n",
              "2     A     A     A     A     A     A     A     A     A     A     A     A   \n",
              "3     A     A     A     A     A     A     A     A     A     A     A     A   \n",
              "4     A     A     A     A     A     A     A     A     A     A     A     A   \n",
              "\n",
              "  cat50 cat51 cat52 cat53 cat54 cat55 cat56 cat57 cat58 cat59 cat60 cat61  \\\n",
              "0     A     A     A     A     A     A     A     A     A     A     A     A   \n",
              "1     A     A     A     A     A     A     A     A     A     A     A     A   \n",
              "2     A     A     A     A     A     A     A     A     A     A     A     A   \n",
              "3     A     A     A     A     A     A     A     A     A     A     A     A   \n",
              "4     A     A     A     A     A     A     A     A     A     A     A     A   \n",
              "\n",
              "  cat62 cat63 cat64 cat65 cat66 cat67 cat68 cat69 cat70 cat71 cat72 cat73  \\\n",
              "0     A     A     A     A     A     A     A     A     A     A     A     A   \n",
              "1     A     A     A     A     A     A     A     A     A     A     A     A   \n",
              "2     A     A     A     A     A     A     A     A     A     A     A     A   \n",
              "3     A     A     A     A     A     A     A     A     A     A     A     B   \n",
              "4     A     A     A     A     A     A     A     A     A     A     B     A   \n",
              "\n",
              "  cat74 cat75 cat76 cat77 cat78 cat79 cat80 cat81 cat82 cat83 cat84 cat85  \\\n",
              "0     A     B     A     D     B     B     D     D     B     D     C     B   \n",
              "1     A     A     A     D     B     B     D     D     A     B     C     B   \n",
              "2     A     A     A     D     B     B     B     D     B     D     C     B   \n",
              "3     A     A     A     D     B     B     D     D     D     B     C     B   \n",
              "4     A     A     A     D     B     D     B     D     B     B     C     B   \n",
              "\n",
              "  cat86 cat87 cat88 cat89 cat90 cat91 cat92 cat93 cat94 cat95 cat96 cat97  \\\n",
              "0     D     B     A     A     A     A     A     D     B     C     E     A   \n",
              "1     D     B     A     A     A     A     A     D     D     C     E     E   \n",
              "2     B     B     A     A     A     A     A     D     D     C     E     E   \n",
              "3     D     B     A     A     A     A     A     D     D     C     E     E   \n",
              "4     B     C     A     A     A     B     H     D     B     D     E     E   \n",
              "\n",
              "  cat98 cat99 cat100 cat101 cat102 cat103 cat104 cat105 cat106 cat107 cat108  \\\n",
              "0     C     T      B      G      A      A      I      E      G      J      G   \n",
              "1     D     T      L      F      A      A      E      E      I      K      K   \n",
              "2     A     D      L      O      A      B      E      F      H      F      A   \n",
              "3     D     T      I      D      A      A      E      E      I      K      K   \n",
              "4     A     P      F      J      A      A      D      E      K      G      B   \n",
              "\n",
              "  cat109 cat110 cat111 cat112 cat113 cat114 cat115 cat116     cont1     cont2  \\\n",
              "0     BU     BC      C     AS      S      A      O     LB  0.726300  0.245921   \n",
              "1     BI     CQ      A     AV     BM      A      O     DP  0.330514  0.737068   \n",
              "2     AB     DK      A      C     AF      A      I     GK  0.261841  0.358319   \n",
              "3     BI     CS      C      N     AE      A      O     DJ  0.321594  0.555782   \n",
              "4      H      C      C      Y     BM      A      K     CK  0.273204  0.159990   \n",
              "\n",
              "      cont3     cont4     cont5     cont6     cont7    cont8    cont9  \\\n",
              "0  0.187583  0.789639  0.310061  0.718367  0.335060  0.30260  0.67135   \n",
              "1  0.592681  0.614134  0.885834  0.438917  0.436585  0.60087  0.35127   \n",
              "2  0.484196  0.236924  0.397069  0.289648  0.315545  0.27320  0.26076   \n",
              "3  0.527991  0.373816  0.422268  0.440945  0.391128  0.31796  0.32128   \n",
              "4  0.527991  0.473202  0.704268  0.178193  0.247408  0.24564  0.22089   \n",
              "\n",
              "    cont10    cont11    cont12    cont13    cont14     loss  \n",
              "0  0.83510  0.569745  0.594646  0.822493  0.714843  2213.18  \n",
              "1  0.43919  0.338312  0.366307  0.611431  0.304496  1283.60  \n",
              "2  0.32446  0.381398  0.373424  0.195709  0.774425  3005.09  \n",
              "3  0.44467  0.327915  0.321570  0.605077  0.602642   939.85  \n",
              "4  0.21230  0.204687  0.202213  0.246011  0.432606  2763.85  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZaLK8L61mkf",
        "outputId": "99b8565c-dc54-444b-a85e-64a3c4d0c2d8"
      },
      "source": [
        "df.info(verbose=True)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 188319 entries, 0 to 188318\n",
            "Data columns (total 132 columns):\n",
            " #   Column  Dtype  \n",
            "---  ------  -----  \n",
            " 0   id      float64\n",
            " 1   cat1    object \n",
            " 2   cat2    object \n",
            " 3   cat3    object \n",
            " 4   cat4    object \n",
            " 5   cat5    object \n",
            " 6   cat6    object \n",
            " 7   cat7    object \n",
            " 8   cat8    object \n",
            " 9   cat9    object \n",
            " 10  cat10   object \n",
            " 11  cat11   object \n",
            " 12  cat12   object \n",
            " 13  cat13   object \n",
            " 14  cat14   object \n",
            " 15  cat15   object \n",
            " 16  cat16   object \n",
            " 17  cat17   object \n",
            " 18  cat18   object \n",
            " 19  cat19   object \n",
            " 20  cat20   object \n",
            " 21  cat21   object \n",
            " 22  cat22   object \n",
            " 23  cat23   object \n",
            " 24  cat24   object \n",
            " 25  cat25   object \n",
            " 26  cat26   object \n",
            " 27  cat27   object \n",
            " 28  cat28   object \n",
            " 29  cat29   object \n",
            " 30  cat30   object \n",
            " 31  cat31   object \n",
            " 32  cat32   object \n",
            " 33  cat33   object \n",
            " 34  cat34   object \n",
            " 35  cat35   object \n",
            " 36  cat36   object \n",
            " 37  cat37   object \n",
            " 38  cat38   object \n",
            " 39  cat39   object \n",
            " 40  cat40   object \n",
            " 41  cat41   object \n",
            " 42  cat42   object \n",
            " 43  cat43   object \n",
            " 44  cat44   object \n",
            " 45  cat45   object \n",
            " 46  cat46   object \n",
            " 47  cat47   object \n",
            " 48  cat48   object \n",
            " 49  cat49   object \n",
            " 50  cat50   object \n",
            " 51  cat51   object \n",
            " 52  cat52   object \n",
            " 53  cat53   object \n",
            " 54  cat54   object \n",
            " 55  cat55   object \n",
            " 56  cat56   object \n",
            " 57  cat57   object \n",
            " 58  cat58   object \n",
            " 59  cat59   object \n",
            " 60  cat60   object \n",
            " 61  cat61   object \n",
            " 62  cat62   object \n",
            " 63  cat63   object \n",
            " 64  cat64   object \n",
            " 65  cat65   object \n",
            " 66  cat66   object \n",
            " 67  cat67   object \n",
            " 68  cat68   object \n",
            " 69  cat69   object \n",
            " 70  cat70   object \n",
            " 71  cat71   object \n",
            " 72  cat72   object \n",
            " 73  cat73   object \n",
            " 74  cat74   object \n",
            " 75  cat75   object \n",
            " 76  cat76   object \n",
            " 77  cat77   object \n",
            " 78  cat78   object \n",
            " 79  cat79   object \n",
            " 80  cat80   object \n",
            " 81  cat81   object \n",
            " 82  cat82   object \n",
            " 83  cat83   object \n",
            " 84  cat84   object \n",
            " 85  cat85   object \n",
            " 86  cat86   object \n",
            " 87  cat87   object \n",
            " 88  cat88   object \n",
            " 89  cat89   object \n",
            " 90  cat90   object \n",
            " 91  cat91   object \n",
            " 92  cat92   object \n",
            " 93  cat93   object \n",
            " 94  cat94   object \n",
            " 95  cat95   object \n",
            " 96  cat96   object \n",
            " 97  cat97   object \n",
            " 98  cat98   object \n",
            " 99  cat99   object \n",
            " 100 cat100  object \n",
            " 101 cat101  object \n",
            " 102 cat102  object \n",
            " 103 cat103  object \n",
            " 104 cat104  object \n",
            " 105 cat105  object \n",
            " 106 cat106  object \n",
            " 107 cat107  object \n",
            " 108 cat108  object \n",
            " 109 cat109  object \n",
            " 110 cat110  object \n",
            " 111 cat111  object \n",
            " 112 cat112  object \n",
            " 113 cat113  object \n",
            " 114 cat114  object \n",
            " 115 cat115  object \n",
            " 116 cat116  object \n",
            " 117 cont1   float64\n",
            " 118 cont2   float64\n",
            " 119 cont3   float64\n",
            " 120 cont4   float64\n",
            " 121 cont5   float64\n",
            " 122 cont6   float64\n",
            " 123 cont7   float64\n",
            " 124 cont8   float64\n",
            " 125 cont9   float64\n",
            " 126 cont10  float64\n",
            " 127 cont11  float64\n",
            " 128 cont12  float64\n",
            " 129 cont13  float64\n",
            " 130 cont14  float64\n",
            " 131 loss    float64\n",
            "dtypes: float64(16), object(116)\n",
            "memory usage: 189.7+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4J7sRXwt2kuz",
        "outputId": "05a083e2-2253-4c90-d02b-dcf1b7b19f2a"
      },
      "source": [
        "df = df.dropna()\n",
        "df.shape"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(188318, 132)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "vcWZfdJGGzXZ",
        "outputId": "5a3c91a2-adc6-4626-de5f-285f9977a1a6"
      },
      "source": [
        "sns.heatmap(df.corr())"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb5ee930d90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWB6Uw-j26Dz"
      },
      "source": [
        "# Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gRdIoraGNZz"
      },
      "source": [
        "data = df[0:5000].copy()\n",
        "y = data['loss']\n",
        "X = data.drop(columns=['loss', 'id'])\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=251)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vtpa33SUGWF7"
      },
      "source": [
        "catColumns = X_train.select_dtypes(include='object').columns.tolist()\n",
        "numColumns = X_train.select_dtypes(include='number').columns.tolist()"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SITXIfo3GLtG"
      },
      "source": [
        "X_train_num = X_train[numColumns]\n",
        "X_test_num  = X_test[numColumns]\n",
        "\n",
        "X_train_cat = X_train[catColumns]\n",
        "X_test_cat  = X_test[catColumns]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "ohe    = OneHotEncoder(variables=catColumns)\n",
        "\n",
        "X_train_num = pd.DataFrame(scaler.fit_transform(X_train_num), columns = X_train_num.columns)\n",
        "X_train_num = X_train_num.reset_index(drop=True)\n",
        "X_test_num  = pd.DataFrame(scaler.transform(X_test_num), columns = X_train_num.columns)\n",
        "X_test_num = X_test_num.reset_index(drop=True)\n",
        "\n",
        "X_train_cat = ohe.fit_transform(X_train_cat)\n",
        "X_train_cat = X_train_cat.reset_index(drop=True)\n",
        "X_test_cat  = ohe.transform(X_test_cat)\n",
        "X_test_cat  = X_test_cat.reset_index(drop=True)\n",
        "\n",
        "X_train = pd.concat([X_train_num, X_train_cat], axis=1)\n",
        "X_test  = pd.concat([X_test_num, X_test_cat], axis=1)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JTSuU28Gc3X"
      },
      "source": [
        "# Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgvIjmAqGXqP"
      },
      "source": [
        "def evaluate(truth, pred):\n",
        "    mae  = mean_absolute_error(truth, pred)\n",
        "    mse  = mean_squared_error(truth, pred)\n",
        "    rmse = math.sqrt(mse)\n",
        "    return (mae, mse, rmse)\n",
        "\n",
        "results_df = pd.DataFrame(columns=['Technique', 'Method', 'MAE', 'RMSE', 'Features'])"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0buTR3FGgki"
      },
      "source": [
        "# Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkJ0zx-HGkSk",
        "outputId": "1d4dae68-159f-4ae0-e0ee-6d554f424d92"
      },
      "source": [
        "rf = RandomForestRegressor(random_state=1337)\n",
        "rf.fit(X_train, y_train)\n",
        "pred = rf.predict(X_test)\n",
        "mae, mse, rmse = evaluate(y_test, pred)\n",
        "print('MAE  : {:.2f}'.format(mae))\n",
        "print('RMSE : {:.2f}'.format(rmse))\n",
        "results_df.loc['Baseline'] = ['None', 'Baseline', mae, rmse, X_train.shape[1]]"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE  : 1365.87\n",
            "RMSE : 2080.47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xnmEIu2GlQM"
      },
      "source": [
        "# Filter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ceoJdNoGn1E"
      },
      "source": [
        "## Highly Correlated\n",
        "* Highly correlated features can lead to overfitting\n",
        "* We can remove highly correlated variables without the loss of much information\n",
        "* EDA indicated:\n",
        "  * cont12 and cont11 highly correlated\n",
        "  * cont9 and cont1 highly correlated"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhjD4DR3Grik"
      },
      "source": [
        "corr_matrix = X_train.corr().abs()\n",
        "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
        "features_to_remove = [column for column in upper.columns if any(upper[column] > 0.95)]"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tdm_VeZ-G5HR",
        "outputId": "b1227b2b-fce4-4222-92cb-4dcaf36b3186"
      },
      "source": [
        "print(features_to_remove) # Note 0.95 > Cont9 > 0.90\n",
        "X_train_new = X_train.drop(columns=features_to_remove, axis=1)\n",
        "X_test_new = X_test.drop(columns=features_to_remove, axis=1)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['cont12', 'cat1_B', 'cat2_A', 'cat3_B', 'cat4_B', 'cat5_B', 'cat6_B', 'cat7_A', 'cat8_A', 'cat9_A', 'cat10_A', 'cat11_A', 'cat12_A', 'cat13_A', 'cat14_B', 'cat16_B', 'cat17_B', 'cat18_B', 'cat19_B', 'cat20_B', 'cat21_B', 'cat22_B', 'cat23_B', 'cat24_B', 'cat25_B', 'cat26_B', 'cat27_B', 'cat28_B', 'cat29_B', 'cat30_B', 'cat31_B', 'cat32_B', 'cat33_B', 'cat34_B', 'cat35_B', 'cat36_B', 'cat37_B', 'cat38_B', 'cat39_B', 'cat40_B', 'cat41_B', 'cat42_B', 'cat43_B', 'cat44_B', 'cat45_B', 'cat46_B', 'cat47_B', 'cat48_B', 'cat49_B', 'cat50_B', 'cat51_B', 'cat52_B', 'cat53_B', 'cat54_B', 'cat55_B', 'cat56_B', 'cat57_A', 'cat58_B', 'cat59_B', 'cat60_B', 'cat61_B', 'cat62_B', 'cat64_B', 'cat65_B', 'cat66_A', 'cat67_B', 'cat68_B', 'cat69_B', 'cat71_B', 'cat72_A', 'cat73_B', 'cat74_B', 'cat75_A', 'cat76_B', 'cat78_A', 'cat80_A', 'cat81_A', 'cat85_A', 'cat87_A', 'cat88_A', 'cat89_B', 'cat89_A', 'cat89_E', 'cat90_A', 'cat90_B', 'cat90_F', 'cat92_H', 'cat93_C', 'cat98_A', 'cat98_E', 'cat99_T', 'cat99_P', 'cat99_R', 'cat99_M', 'cat101_A', 'cat102_A', 'cat103_A', 'cat106_A', 'cat107_A', 'cat108_G', 'cat108_F', 'cat108_C', 'cat108_J', 'cat110_EM', 'cat110_AL', 'cat111_A', 'cat113_G', 'cat114_A', 'cat115_A', 'cat116_MC', 'cat116_B', 'cat116_MP', 'cat116_AK', 'cat116_K', 'cat116_BO', 'cat116_U', 'cat116_R']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Zg-_YobG7QQ",
        "outputId": "83e8f5f0-5462-4602-b66d-c1476856eccd"
      },
      "source": [
        "# Predict & Score\n",
        "rf = RandomForestRegressor(random_state=202)\n",
        "rf.fit(X_train_new, y_train)\n",
        "pred = rf.predict(X_test_new)\n",
        "mae, mse, rmse = evaluate(y_test, pred)\n",
        "print('MAE  : {:.2f}'.format(mae))\n",
        "print('RMSE : {:.2f}'.format(rmse))\n",
        "results_df.loc['Filter:Correlated'] = ['Filter', 'Correlated', mae, rmse, X_train_new.shape[1]]"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE  : 1360.29\n",
            "RMSE : 2080.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJ8zogDmHFOj"
      },
      "source": [
        "## Select Percentile\n",
        "* Univariate Method\n",
        "* Choose your scoring method\n",
        "  * F-Value between label / feature\n",
        "  * Mutual Information\n",
        "* Other selection apporaches\n",
        "  * Select K Best (fixed number)\n",
        "  * Select From Model (choose from importance or coefficients)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGgZh6mUHR4g"
      },
      "source": [
        "## F Score - Regression\n",
        "* Use a linear model for testing the individual effect of a regressor\n",
        "* Scoring function:\n",
        "  * Correlation between regressor & target computed\n",
        "  * Convert to F score\n",
        "  * Convert to p-value\n",
        "  * Take top (n) or percentile of features\n",
        "* For this example. pick upper 10th percentile (~80 features)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eilakADnHbgI",
        "outputId": "426c455a-4ac7-45e6-880e-07ee414098a9"
      },
      "source": [
        "selector = SelectPercentile(f_regression, percentile=10)\n",
        "selector.fit(X_train, y_train)\n",
        "X_train_new = selector.transform(X_train)\n",
        "X_test_new = selector.transform(X_test)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_selection/_univariate_selection.py:299: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  corr /= X_norms\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_selection/_univariate_selection.py:304: RuntimeWarning: invalid value encountered in true_divide\n",
            "  F = corr ** 2 / (1 - corr ** 2) * degrees_of_freedom\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "UQEFTSv7HgSr",
        "outputId": "dafb0d69-5299-473c-c632-0bfdb6f788b6"
      },
      "source": [
        "cols   = X_train.columns[selector.get_support()]\n",
        "pvals  = selector.pvalues_[selector.get_support()]\n",
        "scores = -np.log10(pvals)\n",
        "scores /= scores.max()\n",
        "features_freg_df = pd.DataFrame({'Column': cols, 'P-Value': pvals, 'Score': scores})\n",
        "features_freg_df.sort_values('Score', ascending=False)\n",
        "features_freg_df = features_freg_df.reset_index(drop=True)\n",
        "features_freg_df['Rank'] = features_freg_df.index + 1\n",
        "features_freg_df.head()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Column</th>\n",
              "      <th>P-Value</th>\n",
              "      <th>Score</th>\n",
              "      <th>Rank</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cont2</td>\n",
              "      <td>6.479934e-18</td>\n",
              "      <td>0.071066</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cont3</td>\n",
              "      <td>5.117963e-17</td>\n",
              "      <td>0.067355</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cont7</td>\n",
              "      <td>1.821179e-19</td>\n",
              "      <td>0.077480</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cont11</td>\n",
              "      <td>3.057156e-15</td>\n",
              "      <td>0.060012</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>cont12</td>\n",
              "      <td>7.965805e-16</td>\n",
              "      <td>0.062427</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Column       P-Value     Score  Rank\n",
              "0   cont2  6.479934e-18  0.071066     1\n",
              "1   cont3  5.117963e-17  0.067355     2\n",
              "2   cont7  1.821179e-19  0.077480     3\n",
              "3  cont11  3.057156e-15  0.060012     4\n",
              "4  cont12  7.965805e-16  0.062427     5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptNyzMNyHiHh",
        "outputId": "bda42577-a5fe-4d25-d3ee-200501187d03"
      },
      "source": [
        "# Predict & Score\n",
        "rf = RandomForestRegressor(random_state=999)\n",
        "rf.fit(X_train_new, y_train)\n",
        "pred = rf.predict(X_test_new)\n",
        "mae, mse, rmse = evaluate(y_test, pred)\n",
        "print('MAE  : {:.2f}'.format(mae))\n",
        "print('RMSE : {:.2f}'.format(rmse))\n",
        "results_df.loc['Filter:F-Score'] = ['Filter', 'F-Score', mae, rmse, X_train_new.shape[1]]"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE  : 1438.92\n",
            "RMSE : 2165.38\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XboffZPcHkeC"
      },
      "source": [
        "## Mutual Information\n",
        "* Mutual information measues how much a random variable tells us about another\n",
        "* For example, knowing wind speed could help us guess if a flight will be delayed\n",
        "  * It won't tell us perfectly\n",
        "  * But it could make our guess better\n",
        "  * The degree to to which our guess is better are explained / measured with mutual information\n",
        "* Note:\n",
        "  * Mutual information is not correlation\n",
        "  * Mutual information is more like information gain\n",
        "  * Mutual information is a distance between probability distributions\n",
        "  * Correlation measures the linear relationship between two random variables\n",
        "* In this example, pick upper 10th percentile (about 80 features)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s--WXd5bHxen"
      },
      "source": [
        "selector = SelectPercentile(mutual_info_regression, percentile=10)\n",
        "selector.fit(X_train, y_train)\n",
        "X_train_new = selector.transform(X_train)\n",
        "X_test_new = selector.transform(X_test)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "E7Wxr2WjHz_C",
        "outputId": "fbaff98d-9319-4d7b-d0d9-8e0ce48b6c0e"
      },
      "source": [
        "cols   = X_train.columns[selector.get_support()]\n",
        "scores = selector.scores_[selector.get_support()]\n",
        "scores /= scores.max()\n",
        "features_mut_df = pd.DataFrame({'Column': cols, 'Score': scores})\n",
        "features_mut_df.sort_values('Score', ascending=False)\n",
        "features_mut_df = features_mut_df.reset_index(drop=True)\n",
        "features_mut_df['Rank'] = features_mut_df.index + 1\n",
        "features_mut_df.head()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Column</th>\n",
              "      <th>Score</th>\n",
              "      <th>Rank</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cont2</td>\n",
              "      <td>0.207214</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cont3</td>\n",
              "      <td>0.094443</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cont5</td>\n",
              "      <td>0.101913</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cont7</td>\n",
              "      <td>0.155535</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>cont10</td>\n",
              "      <td>0.116205</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Column     Score  Rank\n",
              "0   cont2  0.207214     1\n",
              "1   cont3  0.094443     2\n",
              "2   cont5  0.101913     3\n",
              "3   cont7  0.155535     4\n",
              "4  cont10  0.116205     5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvrfDljgHz8d",
        "outputId": "6362f6b1-ca84-4792-888b-e366dc136905"
      },
      "source": [
        "# Predict & Score\n",
        "rf = RandomForestRegressor()\n",
        "rf.fit(X_train_new, y_train)\n",
        "pred = rf.predict(X_test_new)\n",
        "mae, mse, rmse = evaluate(y_test, pred)\n",
        "print('MAE  : {:.2f}'.format(mae))\n",
        "print('RMSE : {:.2f}'.format(rmse))\n",
        "results_df.loc['Filter:MutualInformation'] = ['Filter', 'Mutual Information', mae, rmse, X_train_new.shape[1]]"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE  : 1426.22\n",
            "RMSE : 2155.32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvRGkpnqH5zL"
      },
      "source": [
        "## Comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Q5gphXA8H-Dk",
        "outputId": "a9e661ea-1265-4ef3-a19c-bb606ed0e62d"
      },
      "source": [
        "combine_reg_df = features_freg_df[['Column', 'Score', 'Rank']]\n",
        "combine_reg_df = combine_reg_df.rename(columns={'Score': 'FReg:Score', 'Rank':'FReg:Rank'})\n",
        "combine_mut_df = features_mut_df[['Column', 'Score', 'Rank']]\n",
        "combine_mut_df = combine_mut_df.rename(columns={'Score': 'Mut:Score', 'Rank':'Mut:Rank'})\n",
        "\n",
        "features_df = pd.merge(left=combine_reg_df, right=combine_mut_df, how='outer',\n",
        "                      left_on='Column', right_on='Column')\n",
        "features_df"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Column</th>\n",
              "      <th>FReg:Score</th>\n",
              "      <th>FReg:Rank</th>\n",
              "      <th>Mut:Score</th>\n",
              "      <th>Mut:Rank</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cont2</td>\n",
              "      <td>0.071066</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.207214</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cont3</td>\n",
              "      <td>0.067355</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.094443</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cont7</td>\n",
              "      <td>0.077480</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.155535</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cont11</td>\n",
              "      <td>0.060012</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>cont12</td>\n",
              "      <td>0.062427</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.102656</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>cat1_A</td>\n",
              "      <td>0.170950</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.255856</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>cat1_B</td>\n",
              "      <td>0.170950</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.255856</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>cat2_B</td>\n",
              "      <td>0.188197</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.225855</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>cat2_A</td>\n",
              "      <td>0.188197</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.225855</td>\n",
              "      <td>11.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>cat3_A</td>\n",
              "      <td>0.144430</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.114812</td>\n",
              "      <td>12.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>cat3_B</td>\n",
              "      <td>0.144430</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.114812</td>\n",
              "      <td>13.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>cat4_A</td>\n",
              "      <td>0.050528</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.105805</td>\n",
              "      <td>14.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>cat4_B</td>\n",
              "      <td>0.050528</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.105820</td>\n",
              "      <td>15.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>cat7_B</td>\n",
              "      <td>0.333011</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.225240</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>cat7_A</td>\n",
              "      <td>0.333011</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.225240</td>\n",
              "      <td>21.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>cat9_B</td>\n",
              "      <td>0.176220</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.215018</td>\n",
              "      <td>22.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>cat9_A</td>\n",
              "      <td>0.176220</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.215148</td>\n",
              "      <td>23.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>cat10_B</td>\n",
              "      <td>0.334417</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.327630</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>cat10_A</td>\n",
              "      <td>0.334417</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0.329912</td>\n",
              "      <td>25.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>cat11_B</td>\n",
              "      <td>0.229233</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.232275</td>\n",
              "      <td>26.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>cat11_A</td>\n",
              "      <td>0.229233</td>\n",
              "      <td>21.0</td>\n",
              "      <td>0.232275</td>\n",
              "      <td>27.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>cat12_B</td>\n",
              "      <td>0.460972</td>\n",
              "      <td>22.0</td>\n",
              "      <td>0.429911</td>\n",
              "      <td>28.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>cat12_A</td>\n",
              "      <td>0.460972</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.429888</td>\n",
              "      <td>29.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>cat13_B</td>\n",
              "      <td>0.254140</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0.189494</td>\n",
              "      <td>30.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>cat13_A</td>\n",
              "      <td>0.254140</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.189494</td>\n",
              "      <td>31.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>cat16_A</td>\n",
              "      <td>0.151273</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0.136788</td>\n",
              "      <td>32.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>cat16_B</td>\n",
              "      <td>0.151273</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0.137511</td>\n",
              "      <td>33.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>cat23_A</td>\n",
              "      <td>0.122681</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0.169951</td>\n",
              "      <td>34.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>cat23_B</td>\n",
              "      <td>0.122681</td>\n",
              "      <td>29.0</td>\n",
              "      <td>0.170097</td>\n",
              "      <td>35.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>cat24_A</td>\n",
              "      <td>0.061538</td>\n",
              "      <td>30.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>cat24_B</td>\n",
              "      <td>0.061538</td>\n",
              "      <td>31.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>cat25_A</td>\n",
              "      <td>0.041203</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0.072808</td>\n",
              "      <td>36.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>cat25_B</td>\n",
              "      <td>0.041203</td>\n",
              "      <td>33.0</td>\n",
              "      <td>0.072808</td>\n",
              "      <td>37.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>cat28_A</td>\n",
              "      <td>0.098051</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.088355</td>\n",
              "      <td>38.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>cat28_B</td>\n",
              "      <td>0.098051</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0.088463</td>\n",
              "      <td>39.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>cat36_A</td>\n",
              "      <td>0.093478</td>\n",
              "      <td>36.0</td>\n",
              "      <td>0.181062</td>\n",
              "      <td>40.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>cat36_B</td>\n",
              "      <td>0.093478</td>\n",
              "      <td>37.0</td>\n",
              "      <td>0.181062</td>\n",
              "      <td>41.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>cat38_A</td>\n",
              "      <td>0.038593</td>\n",
              "      <td>38.0</td>\n",
              "      <td>0.109045</td>\n",
              "      <td>42.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>cat38_B</td>\n",
              "      <td>0.038593</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0.108536</td>\n",
              "      <td>43.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>cat40_A</td>\n",
              "      <td>0.078473</td>\n",
              "      <td>40.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>cat40_B</td>\n",
              "      <td>0.078473</td>\n",
              "      <td>41.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>cat57_B</td>\n",
              "      <td>0.391370</td>\n",
              "      <td>42.0</td>\n",
              "      <td>0.253829</td>\n",
              "      <td>46.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>cat57_A</td>\n",
              "      <td>0.391370</td>\n",
              "      <td>43.0</td>\n",
              "      <td>0.253829</td>\n",
              "      <td>47.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>cat72_B</td>\n",
              "      <td>0.223248</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0.368493</td>\n",
              "      <td>48.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>cat72_A</td>\n",
              "      <td>0.223248</td>\n",
              "      <td>45.0</td>\n",
              "      <td>0.368331</td>\n",
              "      <td>49.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>cat73_A</td>\n",
              "      <td>0.113043</td>\n",
              "      <td>46.0</td>\n",
              "      <td>0.136179</td>\n",
              "      <td>50.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>cat73_B</td>\n",
              "      <td>0.113043</td>\n",
              "      <td>47.0</td>\n",
              "      <td>0.136179</td>\n",
              "      <td>51.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>cat76_A</td>\n",
              "      <td>0.056215</td>\n",
              "      <td>48.0</td>\n",
              "      <td>0.071443</td>\n",
              "      <td>52.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>cat76_B</td>\n",
              "      <td>0.067040</td>\n",
              "      <td>49.0</td>\n",
              "      <td>0.081171</td>\n",
              "      <td>53.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>cat79_D</td>\n",
              "      <td>0.821749</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0.716452</td>\n",
              "      <td>54.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>cat79_B</td>\n",
              "      <td>0.610738</td>\n",
              "      <td>51.0</td>\n",
              "      <td>0.582195</td>\n",
              "      <td>55.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>cat80_B</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>56.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>cat80_D</td>\n",
              "      <td>0.934752</td>\n",
              "      <td>53.0</td>\n",
              "      <td>0.973192</td>\n",
              "      <td>57.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>cat81_D</td>\n",
              "      <td>0.227108</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.269949</td>\n",
              "      <td>58.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>cat81_B</td>\n",
              "      <td>0.188434</td>\n",
              "      <td>55.0</td>\n",
              "      <td>0.292017</td>\n",
              "      <td>59.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>cat81_C</td>\n",
              "      <td>0.036701</td>\n",
              "      <td>56.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>cat82_D</td>\n",
              "      <td>0.065704</td>\n",
              "      <td>57.0</td>\n",
              "      <td>0.131061</td>\n",
              "      <td>60.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>cat87_B</td>\n",
              "      <td>0.497408</td>\n",
              "      <td>58.0</td>\n",
              "      <td>0.342380</td>\n",
              "      <td>61.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>cat87_D</td>\n",
              "      <td>0.296141</td>\n",
              "      <td>59.0</td>\n",
              "      <td>0.173786</td>\n",
              "      <td>62.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>cat87_C</td>\n",
              "      <td>0.186983</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.157026</td>\n",
              "      <td>63.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>cat89_B</td>\n",
              "      <td>0.312167</td>\n",
              "      <td>61.0</td>\n",
              "      <td>0.201860</td>\n",
              "      <td>64.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>cat89_A</td>\n",
              "      <td>0.333011</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0.225240</td>\n",
              "      <td>65.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>cat90_A</td>\n",
              "      <td>0.144430</td>\n",
              "      <td>63.0</td>\n",
              "      <td>0.114812</td>\n",
              "      <td>66.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>cat90_B</td>\n",
              "      <td>0.136643</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0.120081</td>\n",
              "      <td>67.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>cat92_C</td>\n",
              "      <td>0.046273</td>\n",
              "      <td>65.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>cat94_B</td>\n",
              "      <td>0.044843</td>\n",
              "      <td>66.0</td>\n",
              "      <td>0.080766</td>\n",
              "      <td>68.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>cat94_D</td>\n",
              "      <td>0.045156</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.089783</td>\n",
              "      <td>69.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>cat100_I</td>\n",
              "      <td>0.149685</td>\n",
              "      <td>68.0</td>\n",
              "      <td>0.204881</td>\n",
              "      <td>70.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>cat100_G</td>\n",
              "      <td>0.106083</td>\n",
              "      <td>69.0</td>\n",
              "      <td>0.105955</td>\n",
              "      <td>71.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>cat100_L</td>\n",
              "      <td>0.038727</td>\n",
              "      <td>70.0</td>\n",
              "      <td>0.080839</td>\n",
              "      <td>72.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>cat101_O</td>\n",
              "      <td>0.105256</td>\n",
              "      <td>71.0</td>\n",
              "      <td>0.093800</td>\n",
              "      <td>74.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>cat101_A</td>\n",
              "      <td>0.188197</td>\n",
              "      <td>72.0</td>\n",
              "      <td>0.225817</td>\n",
              "      <td>75.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>cat101_I</td>\n",
              "      <td>0.055831</td>\n",
              "      <td>73.0</td>\n",
              "      <td>0.101065</td>\n",
              "      <td>76.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>cat101_L</td>\n",
              "      <td>0.060323</td>\n",
              "      <td>74.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>cat101_Q</td>\n",
              "      <td>0.118383</td>\n",
              "      <td>75.0</td>\n",
              "      <td>0.111655</td>\n",
              "      <td>77.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>cat101_J</td>\n",
              "      <td>0.039441</td>\n",
              "      <td>76.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>cat101_M</td>\n",
              "      <td>0.087890</td>\n",
              "      <td>77.0</td>\n",
              "      <td>0.078706</td>\n",
              "      <td>78.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>cat105_L</td>\n",
              "      <td>0.074598</td>\n",
              "      <td>78.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>cat109_BI</td>\n",
              "      <td>0.043605</td>\n",
              "      <td>79.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>cat111_A</td>\n",
              "      <td>0.050528</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0.105410</td>\n",
              "      <td>80.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>cat113_E</td>\n",
              "      <td>0.152971</td>\n",
              "      <td>81.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>cat116_KT</td>\n",
              "      <td>0.064872</td>\n",
              "      <td>82.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>cat116_R</td>\n",
              "      <td>0.152971</td>\n",
              "      <td>83.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>cont5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.101913</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>cont10</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.116205</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>cont14</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.136489</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>cat5_A</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.105027</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>cat5_B</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.105180</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>cat6_A</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.110830</td>\n",
              "      <td>18.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>cat6_B</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.110761</td>\n",
              "      <td>19.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>cat50_A</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.179901</td>\n",
              "      <td>44.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>cat50_B</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.180156</td>\n",
              "      <td>45.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>cat100_H</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.074535</td>\n",
              "      <td>73.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>cat103_A</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.104680</td>\n",
              "      <td>79.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>cat114_A</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.110757</td>\n",
              "      <td>81.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>cat114_E</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.082975</td>\n",
              "      <td>82.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>cat114_C</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.150067</td>\n",
              "      <td>83.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Column  FReg:Score  FReg:Rank  Mut:Score  Mut:Rank\n",
              "0       cont2    0.071066        1.0   0.207214       1.0\n",
              "1       cont3    0.067355        2.0   0.094443       2.0\n",
              "2       cont7    0.077480        3.0   0.155535       4.0\n",
              "3      cont11    0.060012        4.0        NaN       NaN\n",
              "4      cont12    0.062427        5.0   0.102656       6.0\n",
              "5      cat1_A    0.170950        6.0   0.255856       8.0\n",
              "6      cat1_B    0.170950        7.0   0.255856       9.0\n",
              "7      cat2_B    0.188197        8.0   0.225855      10.0\n",
              "8      cat2_A    0.188197        9.0   0.225855      11.0\n",
              "9      cat3_A    0.144430       10.0   0.114812      12.0\n",
              "10     cat3_B    0.144430       11.0   0.114812      13.0\n",
              "11     cat4_A    0.050528       12.0   0.105805      14.0\n",
              "12     cat4_B    0.050528       13.0   0.105820      15.0\n",
              "13     cat7_B    0.333011       14.0   0.225240      20.0\n",
              "14     cat7_A    0.333011       15.0   0.225240      21.0\n",
              "15     cat9_B    0.176220       16.0   0.215018      22.0\n",
              "16     cat9_A    0.176220       17.0   0.215148      23.0\n",
              "17    cat10_B    0.334417       18.0   0.327630      24.0\n",
              "18    cat10_A    0.334417       19.0   0.329912      25.0\n",
              "19    cat11_B    0.229233       20.0   0.232275      26.0\n",
              "20    cat11_A    0.229233       21.0   0.232275      27.0\n",
              "21    cat12_B    0.460972       22.0   0.429911      28.0\n",
              "22    cat12_A    0.460972       23.0   0.429888      29.0\n",
              "23    cat13_B    0.254140       24.0   0.189494      30.0\n",
              "24    cat13_A    0.254140       25.0   0.189494      31.0\n",
              "25    cat16_A    0.151273       26.0   0.136788      32.0\n",
              "26    cat16_B    0.151273       27.0   0.137511      33.0\n",
              "27    cat23_A    0.122681       28.0   0.169951      34.0\n",
              "28    cat23_B    0.122681       29.0   0.170097      35.0\n",
              "29    cat24_A    0.061538       30.0        NaN       NaN\n",
              "30    cat24_B    0.061538       31.0        NaN       NaN\n",
              "31    cat25_A    0.041203       32.0   0.072808      36.0\n",
              "32    cat25_B    0.041203       33.0   0.072808      37.0\n",
              "33    cat28_A    0.098051       34.0   0.088355      38.0\n",
              "34    cat28_B    0.098051       35.0   0.088463      39.0\n",
              "35    cat36_A    0.093478       36.0   0.181062      40.0\n",
              "36    cat36_B    0.093478       37.0   0.181062      41.0\n",
              "37    cat38_A    0.038593       38.0   0.109045      42.0\n",
              "38    cat38_B    0.038593       39.0   0.108536      43.0\n",
              "39    cat40_A    0.078473       40.0        NaN       NaN\n",
              "40    cat40_B    0.078473       41.0        NaN       NaN\n",
              "41    cat57_B    0.391370       42.0   0.253829      46.0\n",
              "42    cat57_A    0.391370       43.0   0.253829      47.0\n",
              "43    cat72_B    0.223248       44.0   0.368493      48.0\n",
              "44    cat72_A    0.223248       45.0   0.368331      49.0\n",
              "45    cat73_A    0.113043       46.0   0.136179      50.0\n",
              "46    cat73_B    0.113043       47.0   0.136179      51.0\n",
              "47    cat76_A    0.056215       48.0   0.071443      52.0\n",
              "48    cat76_B    0.067040       49.0   0.081171      53.0\n",
              "49    cat79_D    0.821749       50.0   0.716452      54.0\n",
              "50    cat79_B    0.610738       51.0   0.582195      55.0\n",
              "51    cat80_B    1.000000       52.0   1.000000      56.0\n",
              "52    cat80_D    0.934752       53.0   0.973192      57.0\n",
              "53    cat81_D    0.227108       54.0   0.269949      58.0\n",
              "54    cat81_B    0.188434       55.0   0.292017      59.0\n",
              "55    cat81_C    0.036701       56.0        NaN       NaN\n",
              "56    cat82_D    0.065704       57.0   0.131061      60.0\n",
              "57    cat87_B    0.497408       58.0   0.342380      61.0\n",
              "58    cat87_D    0.296141       59.0   0.173786      62.0\n",
              "59    cat87_C    0.186983       60.0   0.157026      63.0\n",
              "60    cat89_B    0.312167       61.0   0.201860      64.0\n",
              "61    cat89_A    0.333011       62.0   0.225240      65.0\n",
              "62    cat90_A    0.144430       63.0   0.114812      66.0\n",
              "63    cat90_B    0.136643       64.0   0.120081      67.0\n",
              "64    cat92_C    0.046273       65.0        NaN       NaN\n",
              "65    cat94_B    0.044843       66.0   0.080766      68.0\n",
              "66    cat94_D    0.045156       67.0   0.089783      69.0\n",
              "67   cat100_I    0.149685       68.0   0.204881      70.0\n",
              "68   cat100_G    0.106083       69.0   0.105955      71.0\n",
              "69   cat100_L    0.038727       70.0   0.080839      72.0\n",
              "70   cat101_O    0.105256       71.0   0.093800      74.0\n",
              "71   cat101_A    0.188197       72.0   0.225817      75.0\n",
              "72   cat101_I    0.055831       73.0   0.101065      76.0\n",
              "73   cat101_L    0.060323       74.0        NaN       NaN\n",
              "74   cat101_Q    0.118383       75.0   0.111655      77.0\n",
              "75   cat101_J    0.039441       76.0        NaN       NaN\n",
              "76   cat101_M    0.087890       77.0   0.078706      78.0\n",
              "77   cat105_L    0.074598       78.0        NaN       NaN\n",
              "78  cat109_BI    0.043605       79.0        NaN       NaN\n",
              "79   cat111_A    0.050528       80.0   0.105410      80.0\n",
              "80   cat113_E    0.152971       81.0        NaN       NaN\n",
              "81  cat116_KT    0.064872       82.0        NaN       NaN\n",
              "82   cat116_R    0.152971       83.0        NaN       NaN\n",
              "83      cont5         NaN        NaN   0.101913       3.0\n",
              "84     cont10         NaN        NaN   0.116205       5.0\n",
              "85     cont14         NaN        NaN   0.136489       7.0\n",
              "86     cat5_A         NaN        NaN   0.105027      16.0\n",
              "87     cat5_B         NaN        NaN   0.105180      17.0\n",
              "88     cat6_A         NaN        NaN   0.110830      18.0\n",
              "89     cat6_B         NaN        NaN   0.110761      19.0\n",
              "90    cat50_A         NaN        NaN   0.179901      44.0\n",
              "91    cat50_B         NaN        NaN   0.180156      45.0\n",
              "92   cat100_H         NaN        NaN   0.074535      73.0\n",
              "93   cat103_A         NaN        NaN   0.104680      79.0\n",
              "94   cat114_A         NaN        NaN   0.110757      81.0\n",
              "95   cat114_E         NaN        NaN   0.082975      82.0\n",
              "96   cat114_C         NaN        NaN   0.150067      83.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVilzk2YIvyW"
      },
      "source": [
        "## Variance Threshold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B53x7fFJIyxv"
      },
      "source": [
        "selector = VarianceThreshold()\n",
        "selector.fit(X_train)\n",
        "selector.get_support()\n",
        "X_train_new = selector.transform(X_train)\n",
        "X_test_new  = selector.transform(X_test)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcZ9D51GI1qE",
        "outputId": "6dc98d56-b4bc-4d6c-8b2f-1fe9e5af607c"
      },
      "source": [
        "# Predict & Score\n",
        "rf = RandomForestRegressor(random_state=1337)\n",
        "rf.fit(X_train_new, y_train)\n",
        "pred = rf.predict(X_test_new)\n",
        "mae, mse, rmse = evaluate(y_test, pred)\n",
        "print('MAE  : {:.2f}'.format(mae))\n",
        "print('RMSE : {:.2f}'.format(rmse))\n",
        "results_df.loc['Filter:VarianceThreshold'] = ['Filter', 'VarianceThreshold', mae, rmse, X_train_new.shape[1]]"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE  : 1368.46\n",
            "RMSE : 2097.57\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZGkl-EhI4CO"
      },
      "source": [
        "# Embedded\n",
        "* Embedded method use a model to locate the best features.\n",
        "* Broad approaches\n",
        "  * Sparsity - Lasso\n",
        "  * Importance - Random Forest\n",
        "  * Coefficients - Linear Models, SVC / SVR (different than zero)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-hPmACNI-sO"
      },
      "source": [
        "## Lasso Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24JECY_SJGGe",
        "outputId": "0f63f5c6-4650-4d96-91a2-76a87bc298ca"
      },
      "source": [
        "lassoReg = Lasso(fit_intercept=False)\n",
        "lassoReg.fit(X_train, y_train)\n",
        "coefficients = lassoReg.coef_"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 793705974.5595188, tolerance: 7094203.34848626\n",
            "  positive)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMV9ucF4JKSv"
      },
      "source": [
        "support = coefficients > 0\n",
        "cols = X_train.columns[support]\n",
        "X_train_new = X_train[cols]\n",
        "X_test_new = X_test[cols]"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWIDrEo4JKVB",
        "outputId": "df4f4097-1303-4b94-b520-c16179b1dfed"
      },
      "source": [
        "# Predict & Score\n",
        "rf = RandomForestRegressor(random_state=999)\n",
        "rf.fit(X_train_new, y_train)\n",
        "pred = rf.predict(X_test_new)\n",
        "mae, mse, rmse = evaluate(y_test, pred)\n",
        "print('MAE  : {:.2f}'.format(mae))\n",
        "print('RMSE : {:.2f}'.format(rmse))\n",
        "results_df.loc['Embedded:Lasso'] = ['Embedded', 'Lasso', mae, rmse, X_train_new.shape[1]]"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE  : 1367.01\n",
            "RMSE : 2101.34\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1o4RCIXdJSNF"
      },
      "source": [
        "## RandomForest Importance\n",
        "* Common to fit a random forest to look at importance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CR63C9NBJYlB",
        "outputId": "2481e46d-fdd6-4bc4-e859-da08d9b5f9d0"
      },
      "source": [
        "estimator = RandomForestRegressor(random_state=1337)\n",
        "selector = SelectFromModel(estimator, )\n",
        "selector.fit(X_train, y_train)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SelectFromModel(estimator=RandomForestRegressor(bootstrap=True, ccp_alpha=0.0,\n",
              "                                                criterion='mse', max_depth=None,\n",
              "                                                max_features='auto',\n",
              "                                                max_leaf_nodes=None,\n",
              "                                                max_samples=None,\n",
              "                                                min_impurity_decrease=0.0,\n",
              "                                                min_impurity_split=None,\n",
              "                                                min_samples_leaf=1,\n",
              "                                                min_samples_split=2,\n",
              "                                                min_weight_fraction_leaf=0.0,\n",
              "                                                n_estimators=100, n_jobs=None,\n",
              "                                                oob_score=False,\n",
              "                                                random_state=1337, verbose=0,\n",
              "                                                warm_start=False),\n",
              "                max_features=None, norm_order=1, prefit=False, threshold=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYfkopIAJeGO"
      },
      "source": [
        "cols = X_train.columns[(selector.get_support())]\n",
        "X_train_new = X_train[cols]\n",
        "X_test_new  = X_test[cols]"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5ny2OkDJeqA",
        "outputId": "7d4dca53-7cbc-4835-c03a-437f0e5288ad"
      },
      "source": [
        "# Predict & Score\n",
        "rf = RandomForestRegressor(random_state=999)\n",
        "rf.fit(X_train_new, y_train)\n",
        "pred = rf.predict(X_test_new)\n",
        "mae, mse, rmse = evaluate(y_test, pred)\n",
        "print('MAE  : {:.2f}'.format(mae))\n",
        "print('RMSE : {:.2f}'.format(rmse))\n",
        "results_df.loc['Embedded:RandomForest'] = ['Embedded', 'RandomForest', mae, rmse, X_train_new.shape[1]]"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE  : 1372.25\n",
            "RMSE : 2080.25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "6gPx8v4KJesl",
        "outputId": "04c8e19c-12a7-4e5f-de39-85f8df50dd48"
      },
      "source": [
        "features = {}\n",
        "for feature, importance in zip(X_train_new.columns, rf.feature_importances_):\n",
        "    features[feature] = importance\n",
        "importanceDF = pd.DataFrame.from_dict(features, orient='index')\n",
        "importanceDF.sort_values(by=0, ascending=False).head(10)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>cat80_B</th>\n",
              "      <td>0.242401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cont2</th>\n",
              "      <td>0.052100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cont7</th>\n",
              "      <td>0.051350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cont14</th>\n",
              "      <td>0.043476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cont3</th>\n",
              "      <td>0.037110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cat57_A</th>\n",
              "      <td>0.023621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cont8</th>\n",
              "      <td>0.022725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cont11</th>\n",
              "      <td>0.022408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cont4</th>\n",
              "      <td>0.021076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cont12</th>\n",
              "      <td>0.020660</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                0\n",
              "cat80_B  0.242401\n",
              "cont2    0.052100\n",
              "cont7    0.051350\n",
              "cont14   0.043476\n",
              "cont3    0.037110\n",
              "cat57_A  0.023621\n",
              "cont8    0.022725\n",
              "cont11   0.022408\n",
              "cont4    0.021076\n",
              "cont12   0.020660"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 543
        },
        "id": "v4eGIBzVJn0w",
        "outputId": "85dccca9-aee1-46ab-b81f-0c4e669cbcb3"
      },
      "source": [
        "importanceDF.sort_values(by=0, ascending=False)[0:25].plot(kind='bar', rot=90, figsize=(10, 8))\n",
        "plt.title('Top 25 Important Features');"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5-3XyFtJpvz"
      },
      "source": [
        "# Wrapper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjYxsKmVJuLc"
      },
      "source": [
        "## Recursive Feature Elimination\n",
        "* We start with a full model (all features)\n",
        "* We then remove one feature and construct a model\n",
        "* Greedily select the model with the lowest error\n",
        "* Repeat until desired number of features or precisin is met"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cp-LRDfdJ22_",
        "outputId": "874cbde1-3d4c-4acf-c291-91f0bbed7335"
      },
      "source": [
        "estimator = SVR(kernel=\"linear\")\n",
        "selector = RFE(estimator, 80, step=10, verbose=1)\n",
        "selector = selector.fit(X_train, y_train)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting estimator with 828 features.\n",
            "Fitting estimator with 818 features.\n",
            "Fitting estimator with 808 features.\n",
            "Fitting estimator with 798 features.\n",
            "Fitting estimator with 788 features.\n",
            "Fitting estimator with 778 features.\n",
            "Fitting estimator with 768 features.\n",
            "Fitting estimator with 758 features.\n",
            "Fitting estimator with 748 features.\n",
            "Fitting estimator with 738 features.\n",
            "Fitting estimator with 728 features.\n",
            "Fitting estimator with 718 features.\n",
            "Fitting estimator with 708 features.\n",
            "Fitting estimator with 698 features.\n",
            "Fitting estimator with 688 features.\n",
            "Fitting estimator with 678 features.\n",
            "Fitting estimator with 668 features.\n",
            "Fitting estimator with 658 features.\n",
            "Fitting estimator with 648 features.\n",
            "Fitting estimator with 638 features.\n",
            "Fitting estimator with 628 features.\n",
            "Fitting estimator with 618 features.\n",
            "Fitting estimator with 608 features.\n",
            "Fitting estimator with 598 features.\n",
            "Fitting estimator with 588 features.\n",
            "Fitting estimator with 578 features.\n",
            "Fitting estimator with 568 features.\n",
            "Fitting estimator with 558 features.\n",
            "Fitting estimator with 548 features.\n",
            "Fitting estimator with 538 features.\n",
            "Fitting estimator with 528 features.\n",
            "Fitting estimator with 518 features.\n",
            "Fitting estimator with 508 features.\n",
            "Fitting estimator with 498 features.\n",
            "Fitting estimator with 488 features.\n",
            "Fitting estimator with 478 features.\n",
            "Fitting estimator with 468 features.\n",
            "Fitting estimator with 458 features.\n",
            "Fitting estimator with 448 features.\n",
            "Fitting estimator with 438 features.\n",
            "Fitting estimator with 428 features.\n",
            "Fitting estimator with 418 features.\n",
            "Fitting estimator with 408 features.\n",
            "Fitting estimator with 398 features.\n",
            "Fitting estimator with 388 features.\n",
            "Fitting estimator with 378 features.\n",
            "Fitting estimator with 368 features.\n",
            "Fitting estimator with 358 features.\n",
            "Fitting estimator with 348 features.\n",
            "Fitting estimator with 338 features.\n",
            "Fitting estimator with 328 features.\n",
            "Fitting estimator with 318 features.\n",
            "Fitting estimator with 308 features.\n",
            "Fitting estimator with 298 features.\n",
            "Fitting estimator with 288 features.\n",
            "Fitting estimator with 278 features.\n",
            "Fitting estimator with 268 features.\n",
            "Fitting estimator with 258 features.\n",
            "Fitting estimator with 248 features.\n",
            "Fitting estimator with 238 features.\n",
            "Fitting estimator with 228 features.\n",
            "Fitting estimator with 218 features.\n",
            "Fitting estimator with 208 features.\n",
            "Fitting estimator with 198 features.\n",
            "Fitting estimator with 188 features.\n",
            "Fitting estimator with 178 features.\n",
            "Fitting estimator with 168 features.\n",
            "Fitting estimator with 158 features.\n",
            "Fitting estimator with 148 features.\n",
            "Fitting estimator with 138 features.\n",
            "Fitting estimator with 128 features.\n",
            "Fitting estimator with 118 features.\n",
            "Fitting estimator with 108 features.\n",
            "Fitting estimator with 98 features.\n",
            "Fitting estimator with 88 features.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFEClUvcJ6bl"
      },
      "source": [
        "X_train_new = selector.transform(X_train)\n",
        "X_test_new  = selector.transform(X_test)"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfkSFwJaJ6eH",
        "outputId": "74b5ea1a-d41c-40e6-90eb-d49e1d257840"
      },
      "source": [
        "# Predict & Score\n",
        "rf = RandomForestRegressor(random_state=999)\n",
        "rf.fit(X_train_new, y_train)\n",
        "pred = rf.predict(X_test_new)\n",
        "mae, mse, rmse = evaluate(y_test, pred)\n",
        "print('MAE  : {:.2f}'.format(mae))\n",
        "print('RMSE : {:.2f}'.format(rmse))\n",
        "results_df.loc['Wrapper:RFE'] = ['Wrapper', 'RFE', mae, rmse, X_train_new.shape[1]]"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE  : 1399.74\n",
            "RMSE : 2108.81\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQBODqUFJ-bf"
      },
      "source": [
        "## Sequential Forward Selection\n",
        "* There isn't a forward selection in sklearn\n",
        "* The mlxtend library has a robust implementation\n",
        "  * Parallel\n",
        "  * Plotting\n",
        "  * Target range\n",
        "  * Includes float (https://www.sciencedirect.com/science/article/pii/0167865594901279)\n",
        "* With SFS we start with an empty model\n",
        "* Build a separate model for each additional feature\n",
        "* Greedily select best model\n",
        "* Repeat until desired number of features or precision reached"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEngjDYkKKAy"
      },
      "source": [
        "estimator = LinearRegression()\n",
        "sfs = SFS(estimator,\n",
        "         k_features=80,\n",
        "         forward=True,\n",
        "         floating=False,\n",
        "         verbose=2,\n",
        "         scoring='neg_mean_squared_error',\n",
        "         n_jobs=-1,\n",
        "         cv=0)"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiOVi_YLKPVk",
        "outputId": "7046d6a5-4bb9-4bcc-e7bc-4f2efc9b0712"
      },
      "source": [
        "sfsModel = sfs.fit(X_train, y_train)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 328 tasks      | elapsed:    1.7s\n",
            "[Parallel(n_jobs=-1)]: Done 828 out of 828 | elapsed:    2.2s finished\n",
            "\n",
            "[2021-06-30 18:45:14] Features: 1/80 -- score: -6416706.87302631[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 785 tasks      | elapsed:    0.8s\n",
            "[Parallel(n_jobs=-1)]: Done 824 out of 827 | elapsed:    0.9s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done 827 out of 827 | elapsed:    0.9s finished\n",
            "\n",
            "[2021-06-30 18:45:15] Features: 2/80 -- score: -5980323.971271509[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 785 tasks      | elapsed:    0.9s\n",
            "[Parallel(n_jobs=-1)]: Done 826 out of 826 | elapsed:    1.0s finished\n",
            "\n",
            "[2021-06-30 18:45:16] Features: 3/80 -- score: -5644577.549045111[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 779 tasks      | elapsed:    0.9s\n",
            "[Parallel(n_jobs=-1)]: Done 825 out of 825 | elapsed:    1.1s finished\n",
            "\n",
            "[2021-06-30 18:45:17] Features: 4/80 -- score: -5363158.29368068[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 779 tasks      | elapsed:    1.1s\n",
            "[Parallel(n_jobs=-1)]: Done 821 out of 824 | elapsed:    1.2s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done 824 out of 824 | elapsed:    1.2s finished\n",
            "\n",
            "[2021-06-30 18:45:18] Features: 5/80 -- score: -5156481.856029088[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 774 tasks      | elapsed:    1.1s\n",
            "[Parallel(n_jobs=-1)]: Done 820 out of 823 | elapsed:    1.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done 823 out of 823 | elapsed:    1.3s finished\n",
            "\n",
            "[2021-06-30 18:45:20] Features: 6/80 -- score: -4987744.242407002[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 774 tasks      | elapsed:    1.1s\n",
            "[Parallel(n_jobs=-1)]: Done 822 out of 822 | elapsed:    1.3s finished\n",
            "\n",
            "[2021-06-30 18:45:21] Features: 7/80 -- score: -4857075.156109168[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 774 tasks      | elapsed:    1.1s\n",
            "[Parallel(n_jobs=-1)]: Done 818 out of 821 | elapsed:    1.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done 821 out of 821 | elapsed:    1.3s finished\n",
            "\n",
            "[2021-06-30 18:45:23] Features: 8/80 -- score: -4717056.887760343[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 774 tasks      | elapsed:    1.3s\n",
            "[Parallel(n_jobs=-1)]: Done 820 out of 820 | elapsed:    1.5s finished\n",
            "\n",
            "[2021-06-30 18:45:24] Features: 9/80 -- score: -4637272.938958035[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 774 tasks      | elapsed:    1.4s\n",
            "[Parallel(n_jobs=-1)]: Done 816 out of 819 | elapsed:    1.6s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done 819 out of 819 | elapsed:    1.6s finished\n",
            "\n",
            "[2021-06-30 18:45:26] Features: 10/80 -- score: -4562033.247991452[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 774 tasks      | elapsed:    1.6s\n",
            "[Parallel(n_jobs=-1)]: Done 818 out of 818 | elapsed:    1.8s finished\n",
            "\n",
            "[2021-06-30 18:45:28] Features: 11/80 -- score: -4497152.346010687[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 774 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done 814 out of 817 | elapsed:    1.7s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done 817 out of 817 | elapsed:    1.7s finished\n",
            "\n",
            "[2021-06-30 18:45:29] Features: 12/80 -- score: -4443469.1923009325[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 774 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done 816 out of 816 | elapsed:    1.7s finished\n",
            "\n",
            "[2021-06-30 18:45:31] Features: 13/80 -- score: -4391405.333414539[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 774 tasks      | elapsed:    1.6s\n",
            "[Parallel(n_jobs=-1)]: Done 812 out of 815 | elapsed:    1.8s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done 815 out of 815 | elapsed:    1.8s finished\n",
            "\n",
            "[2021-06-30 18:45:33] Features: 14/80 -- score: -4343383.573614605[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 668 tasks      | elapsed:    1.7s\n",
            "[Parallel(n_jobs=-1)]: Done 814 out of 814 | elapsed:    2.1s finished\n",
            "\n",
            "[2021-06-30 18:45:35] Features: 15/80 -- score: -4289275.2905008895[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 668 tasks      | elapsed:    1.8s\n",
            "[Parallel(n_jobs=-1)]: Done 810 out of 813 | elapsed:    2.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done 813 out of 813 | elapsed:    2.1s finished\n",
            "\n",
            "[2021-06-30 18:45:38] Features: 16/80 -- score: -4238821.841517398[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 668 tasks      | elapsed:    1.7s\n",
            "[Parallel(n_jobs=-1)]: Done 812 out of 812 | elapsed:    2.1s finished\n",
            "\n",
            "[2021-06-30 18:45:40] Features: 17/80 -- score: -4194505.676147479[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 668 tasks      | elapsed:    2.0s\n",
            "[Parallel(n_jobs=-1)]: Done 808 out of 811 | elapsed:    2.4s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done 811 out of 811 | elapsed:    2.4s finished\n",
            "\n",
            "[2021-06-30 18:45:42] Features: 18/80 -- score: -4153223.9606044483[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 668 tasks      | elapsed:    1.9s\n",
            "[Parallel(n_jobs=-1)]: Done 810 out of 810 | elapsed:    2.3s finished\n",
            "\n",
            "[2021-06-30 18:45:45] Features: 19/80 -- score: -4118599.385203314[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 668 tasks      | elapsed:    1.9s\n",
            "[Parallel(n_jobs=-1)]: Done 806 out of 809 | elapsed:    2.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done 809 out of 809 | elapsed:    2.4s finished\n",
            "\n",
            "[2021-06-30 18:45:47] Features: 20/80 -- score: -4086544.5727020893[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 668 tasks      | elapsed:    2.0s\n",
            "[Parallel(n_jobs=-1)]: Done 808 out of 808 | elapsed:    2.4s finished\n",
            "\n",
            "[2021-06-30 18:45:50] Features: 21/80 -- score: -4056921.8664511065[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 668 tasks      | elapsed:    2.0s\n",
            "[Parallel(n_jobs=-1)]: Done 804 out of 807 | elapsed:    2.5s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done 807 out of 807 | elapsed:    2.5s finished\n",
            "\n",
            "[2021-06-30 18:45:53] Features: 22/80 -- score: -4027736.8071285724[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 668 tasks      | elapsed:    2.1s\n",
            "[Parallel(n_jobs=-1)]: Done 806 out of 806 | elapsed:    2.5s finished\n",
            "\n",
            "[2021-06-30 18:45:55] Features: 23/80 -- score: -4002293.1360181766[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 668 tasks      | elapsed:    2.2s\n",
            "[Parallel(n_jobs=-1)]: Done 802 out of 805 | elapsed:    2.6s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done 805 out of 805 | elapsed:    2.7s finished\n",
            "\n",
            "[2021-06-30 18:45:58] Features: 24/80 -- score: -3976409.451182293[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 668 tasks      | elapsed:    2.3s\n",
            "[Parallel(n_jobs=-1)]: Done 804 out of 804 | elapsed:    2.7s finished\n",
            "\n",
            "[2021-06-30 18:46:01] Features: 25/80 -- score: -3951300.238726309[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 668 tasks      | elapsed:    2.3s\n",
            "[Parallel(n_jobs=-1)]: Done 803 out of 803 | elapsed:    2.9s finished\n",
            "\n",
            "[2021-06-30 18:46:04] Features: 26/80 -- score: -3927797.367701658[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 668 tasks      | elapsed:    2.7s\n",
            "[Parallel(n_jobs=-1)]: Done 802 out of 802 | elapsed:    3.4s finished\n",
            "\n",
            "[2021-06-30 18:46:07] Features: 27/80 -- score: -3904025.3177079977[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 668 tasks      | elapsed:    2.5s\n",
            "[Parallel(n_jobs=-1)]: Done 801 out of 801 | elapsed:    3.2s finished\n",
            "\n",
            "[2021-06-30 18:46:11] Features: 28/80 -- score: -3875893.902547388[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 668 tasks      | elapsed:    2.6s\n",
            "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:    3.3s finished\n",
            "\n",
            "[2021-06-30 18:46:14] Features: 29/80 -- score: -3853229.1814553267[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 668 tasks      | elapsed:    2.8s\n",
            "[Parallel(n_jobs=-1)]: Done 799 out of 799 | elapsed:    3.4s finished\n",
            "\n",
            "[2021-06-30 18:46:18] Features: 30/80 -- score: -3831987.9008010626[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 396 tasks      | elapsed:    1.8s\n",
            "[Parallel(n_jobs=-1)]: Done 798 out of 798 | elapsed:    3.4s finished\n",
            "\n",
            "[2021-06-30 18:46:21] Features: 31/80 -- score: -3815224.1444222173[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 396 tasks      | elapsed:    1.9s\n",
            "[Parallel(n_jobs=-1)]: Done 797 out of 797 | elapsed:    3.8s finished\n",
            "\n",
            "[2021-06-30 18:46:25] Features: 32/80 -- score: -3798996.00775548[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 396 tasks      | elapsed:    2.0s\n",
            "[Parallel(n_jobs=-1)]: Done 796 out of 796 | elapsed:    3.7s finished\n",
            "\n",
            "[2021-06-30 18:46:29] Features: 33/80 -- score: -3783428.019034807[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 396 tasks      | elapsed:    2.0s\n",
            "[Parallel(n_jobs=-1)]: Done 795 out of 795 | elapsed:    4.0s finished\n",
            "\n",
            "[2021-06-30 18:46:33] Features: 34/80 -- score: -3767213.656244835[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 396 tasks      | elapsed:    2.1s\n",
            "[Parallel(n_jobs=-1)]: Done 794 out of 794 | elapsed:    4.1s finished\n",
            "\n",
            "[2021-06-30 18:46:37] Features: 35/80 -- score: -3751463.4807139216[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 396 tasks      | elapsed:    2.3s\n",
            "[Parallel(n_jobs=-1)]: Done 793 out of 793 | elapsed:    4.6s finished\n",
            "\n",
            "[2021-06-30 18:46:42] Features: 36/80 -- score: -3735920.9862751802[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 396 tasks      | elapsed:    2.2s\n",
            "[Parallel(n_jobs=-1)]: Done 792 out of 792 | elapsed:    4.3s finished\n",
            "\n",
            "[2021-06-30 18:46:46] Features: 37/80 -- score: -3721756.519363892[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 396 tasks      | elapsed:    2.2s\n",
            "[Parallel(n_jobs=-1)]: Done 791 out of 791 | elapsed:    4.4s finished\n",
            "\n",
            "[2021-06-30 18:46:51] Features: 38/80 -- score: -3708282.9048516494[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 396 tasks      | elapsed:    2.3s\n",
            "[Parallel(n_jobs=-1)]: Done 790 out of 790 | elapsed:    4.9s finished\n",
            "\n",
            "[2021-06-30 18:46:56] Features: 39/80 -- score: -3695542.1242018384[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 396 tasks      | elapsed:    2.5s\n",
            "[Parallel(n_jobs=-1)]: Done 789 out of 789 | elapsed:    4.8s finished\n",
            "\n",
            "[2021-06-30 18:47:01] Features: 40/80 -- score: -3682505.6835912713[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 396 tasks      | elapsed:    2.5s\n",
            "[Parallel(n_jobs=-1)]: Done 788 out of 788 | elapsed:    4.9s finished\n",
            "\n",
            "[2021-06-30 18:47:06] Features: 41/80 -- score: -3669358.70133878[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 396 tasks      | elapsed:    2.6s\n",
            "[Parallel(n_jobs=-1)]: Done 787 out of 787 | elapsed:    5.0s finished\n",
            "\n",
            "[2021-06-30 18:47:11] Features: 42/80 -- score: -3657848.1793043055[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 396 tasks      | elapsed:    2.7s\n",
            "[Parallel(n_jobs=-1)]: Done 786 out of 786 | elapsed:    5.2s finished\n",
            "\n",
            "[2021-06-30 18:47:16] Features: 43/80 -- score: -3646704.0387016395[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 396 tasks      | elapsed:    3.0s\n",
            "[Parallel(n_jobs=-1)]: Done 785 out of 785 | elapsed:    5.6s finished\n",
            "\n",
            "[2021-06-30 18:47:22] Features: 44/80 -- score: -3635777.9541846695[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 396 tasks      | elapsed:    2.8s\n",
            "[Parallel(n_jobs=-1)]: Done 784 out of 784 | elapsed:    5.5s finished\n",
            "\n",
            "[2021-06-30 18:47:28] Features: 45/80 -- score: -3624828.287384015[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 228 tasks      | elapsed:    1.8s\n",
            "[Parallel(n_jobs=-1)]: Done 783 out of 783 | elapsed:    5.8s finished\n",
            "\n",
            "[2021-06-30 18:47:34] Features: 46/80 -- score: -3615051.377385092[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 396 tasks      | elapsed:    3.0s\n",
            "[Parallel(n_jobs=-1)]: Done 782 out of 782 | elapsed:    6.0s finished\n",
            "\n",
            "[2021-06-30 18:47:40] Features: 47/80 -- score: -3605835.167138369[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 396 tasks      | elapsed:    3.2s\n",
            "[Parallel(n_jobs=-1)]: Done 781 out of 781 | elapsed:    6.1s finished\n",
            "\n",
            "[2021-06-30 18:47:46] Features: 48/80 -- score: -3596990.8411734914[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 228 tasks      | elapsed:    1.9s\n",
            "[Parallel(n_jobs=-1)]: Done 780 out of 780 | elapsed:    6.4s finished\n",
            "\n",
            "[2021-06-30 18:47:52] Features: 49/80 -- score: -3587518.314790743[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 228 tasks      | elapsed:    2.1s\n",
            "[Parallel(n_jobs=-1)]: Done 779 out of 779 | elapsed:    7.0s finished\n",
            "\n",
            "[2021-06-30 18:47:59] Features: 50/80 -- score: -3578602.2547946493[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 228 tasks      | elapsed:    2.3s\n",
            "[Parallel(n_jobs=-1)]: Done 778 out of 778 | elapsed:    7.6s finished\n",
            "\n",
            "[2021-06-30 18:48:07] Features: 51/80 -- score: -3570331.413636953[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 228 tasks      | elapsed:    2.5s\n",
            "[Parallel(n_jobs=-1)]: Done 777 out of 777 | elapsed:    7.8s finished\n",
            "\n",
            "[2021-06-30 18:48:15] Features: 52/80 -- score: -3562288.9298291276[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 228 tasks      | elapsed:    2.3s\n",
            "[Parallel(n_jobs=-1)]: Done 776 out of 776 | elapsed:    7.8s finished\n",
            "\n",
            "[2021-06-30 18:48:23] Features: 53/80 -- score: -3554170.6122466964[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 228 tasks      | elapsed:    2.5s\n",
            "[Parallel(n_jobs=-1)]: Done 775 out of 775 | elapsed:    8.0s finished\n",
            "\n",
            "[2021-06-30 18:48:31] Features: 54/80 -- score: -3546021.963514633[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 228 tasks      | elapsed:    2.5s\n",
            "[Parallel(n_jobs=-1)]: Done 774 out of 774 | elapsed:    8.6s finished\n",
            "\n",
            "[2021-06-30 18:48:40] Features: 55/80 -- score: -3538394.732908837[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 228 tasks      | elapsed:    2.6s\n",
            "[Parallel(n_jobs=-1)]: Done 773 out of 773 | elapsed:    8.4s finished\n",
            "\n",
            "[2021-06-30 18:48:48] Features: 56/80 -- score: -3531784.438263771[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 228 tasks      | elapsed:    2.6s\n",
            "[Parallel(n_jobs=-1)]: Done 772 out of 772 | elapsed:    8.5s finished\n",
            "\n",
            "[2021-06-30 18:48:57] Features: 57/80 -- score: -3525159.8811501865[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 228 tasks      | elapsed:    2.7s\n",
            "[Parallel(n_jobs=-1)]: Done 771 out of 771 | elapsed:    9.0s finished\n",
            "\n",
            "[2021-06-30 18:49:06] Features: 58/80 -- score: -3518694.807340677[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 228 tasks      | elapsed:    2.8s\n",
            "[Parallel(n_jobs=-1)]: Done 770 out of 770 | elapsed:    9.0s finished\n",
            "\n",
            "[2021-06-30 18:49:15] Features: 59/80 -- score: -3511886.528608413[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 228 tasks      | elapsed:    2.8s\n",
            "[Parallel(n_jobs=-1)]: Done 769 out of 769 | elapsed:    9.1s finished\n",
            "\n",
            "[2021-06-30 18:49:24] Features: 60/80 -- score: -3505648.666393753[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 228 tasks      | elapsed:    2.9s\n",
            "[Parallel(n_jobs=-1)]: Done 768 out of 768 | elapsed:    9.3s finished\n",
            "\n",
            "[2021-06-30 18:49:34] Features: 61/80 -- score: -3499563.4787224224[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 228 tasks      | elapsed:    3.1s\n",
            "[Parallel(n_jobs=-1)]: Done 767 out of 767 | elapsed:    9.7s finished\n",
            "\n",
            "[2021-06-30 18:49:44] Features: 62/80 -- score: -3493735.817313223[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 228 tasks      | elapsed:    3.1s\n",
            "[Parallel(n_jobs=-1)]: Done 766 out of 766 | elapsed:    9.8s finished\n",
            "\n",
            "[2021-06-30 18:49:54] Features: 63/80 -- score: -3488299.1133430377[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 228 tasks      | elapsed:    3.2s\n",
            "[Parallel(n_jobs=-1)]: Done 765 out of 765 | elapsed:   10.3s finished\n",
            "\n",
            "[2021-06-30 18:50:04] Features: 64/80 -- score: -3483259.5299454653[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed:    2.2s\n",
            "[Parallel(n_jobs=-1)]: Done 612 tasks      | elapsed:    9.6s\n",
            "[Parallel(n_jobs=-1)]: Done 764 out of 764 | elapsed:   11.9s finished\n",
            "\n",
            "[2021-06-30 18:50:16] Features: 65/80 -- score: -3477979.8086421[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 220 tasks      | elapsed:    3.2s\n",
            "[Parallel(n_jobs=-1)]: Done 763 out of 763 | elapsed:   10.8s finished\n",
            "\n",
            "[2021-06-30 18:50:27] Features: 66/80 -- score: -3473043.080180799[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 228 tasks      | elapsed:    3.3s\n",
            "[Parallel(n_jobs=-1)]: Done 762 out of 762 | elapsed:   11.0s finished\n",
            "\n",
            "[2021-06-30 18:50:38] Features: 67/80 -- score: -3468129.5049798596[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 228 tasks      | elapsed:    3.5s\n",
            "[Parallel(n_jobs=-1)]: Done 761 out of 761 | elapsed:   11.0s finished\n",
            "\n",
            "[2021-06-30 18:50:49] Features: 68/80 -- score: -3463233.0967985704[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 228 tasks      | elapsed:    3.4s\n",
            "[Parallel(n_jobs=-1)]: Done 760 out of 760 | elapsed:   11.0s finished\n",
            "\n",
            "[2021-06-30 18:51:00] Features: 69/80 -- score: -3458563.405557819[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 228 tasks      | elapsed:    3.5s\n",
            "[Parallel(n_jobs=-1)]: Done 759 out of 759 | elapsed:   11.2s finished\n",
            "\n",
            "[2021-06-30 18:51:12] Features: 70/80 -- score: -3454289.9580112942[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed:    2.2s\n",
            "[Parallel(n_jobs=-1)]: Done 612 tasks      | elapsed:   10.1s\n",
            "[Parallel(n_jobs=-1)]: Done 758 out of 758 | elapsed:   12.5s finished\n",
            "\n",
            "[2021-06-30 18:51:24] Features: 71/80 -- score: -3449982.6130594388[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 228 tasks      | elapsed:    3.6s\n",
            "[Parallel(n_jobs=-1)]: Done 757 out of 757 | elapsed:   11.7s finished\n",
            "\n",
            "[2021-06-30 18:51:36] Features: 72/80 -- score: -3445864.909542436[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed:    2.3s\n",
            "[Parallel(n_jobs=-1)]: Done 612 tasks      | elapsed:   10.4s\n",
            "[Parallel(n_jobs=-1)]: Done 756 out of 756 | elapsed:   12.9s finished\n",
            "\n",
            "[2021-06-30 18:51:49] Features: 73/80 -- score: -3441812.0891979197[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=-1)]: Done 612 tasks      | elapsed:   10.6s\n",
            "[Parallel(n_jobs=-1)]: Done 755 out of 755 | elapsed:   13.1s finished\n",
            "\n",
            "[2021-06-30 18:52:02] Features: 74/80 -- score: -3437743.750648755[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=-1)]: Done 612 tasks      | elapsed:   11.1s\n",
            "[Parallel(n_jobs=-1)]: Done 754 out of 754 | elapsed:   13.6s finished\n",
            "\n",
            "[2021-06-30 18:52:16] Features: 75/80 -- score: -3433858.319383381[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=-1)]: Done 612 tasks      | elapsed:   11.1s\n",
            "[Parallel(n_jobs=-1)]: Done 753 out of 753 | elapsed:   13.6s finished\n",
            "\n",
            "[2021-06-30 18:52:30] Features: 76/80 -- score: -3429994.2012860957[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed:    2.6s\n",
            "[Parallel(n_jobs=-1)]: Done 612 tasks      | elapsed:   11.5s\n",
            "[Parallel(n_jobs=-1)]: Done 752 out of 752 | elapsed:   14.1s finished\n",
            "\n",
            "[2021-06-30 18:52:44] Features: 77/80 -- score: -3426387.1840713155[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed:    2.5s\n",
            "[Parallel(n_jobs=-1)]: Done 612 tasks      | elapsed:   11.7s\n",
            "[Parallel(n_jobs=-1)]: Done 751 out of 751 | elapsed:   14.3s finished\n",
            "\n",
            "[2021-06-30 18:52:58] Features: 78/80 -- score: -3422550.3034549984[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed:    2.6s\n",
            "[Parallel(n_jobs=-1)]: Done 612 tasks      | elapsed:   11.8s\n",
            "[Parallel(n_jobs=-1)]: Done 750 out of 750 | elapsed:   14.4s finished\n",
            "\n",
            "[2021-06-30 18:53:13] Features: 79/80 -- score: -3418988.656630802[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed:    2.6s\n",
            "[Parallel(n_jobs=-1)]: Done 612 tasks      | elapsed:   12.2s\n",
            "[Parallel(n_jobs=-1)]: Done 749 out of 749 | elapsed:   14.9s finished\n",
            "\n",
            "[2021-06-30 18:53:28] Features: 80/80 -- score: -3415348.486636858"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "KCghNHGDKT9a",
        "outputId": "adc4dd2a-3437-4058-a64c-5ee64dc88672"
      },
      "source": [
        "plot_sfs(sfsModel.get_metric_dict())\n",
        "plt.title('Sequential Forward Selection')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:234: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  keepdims=keepdims)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfmGmstxKVnQ"
      },
      "source": [
        "features = list(sfsModel.subsets_[80]['feature_names'])\n",
        "X_train_new = X_train[features]\n",
        "X_test_new  = X_test[features]"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYKujQo8KXXS",
        "outputId": "5308f87d-4263-4e4c-f9ee-3bab8102103e"
      },
      "source": [
        "# Predict & Score\n",
        "rf = RandomForestRegressor(random_state=999)\n",
        "rf.fit(X_train_new, y_train)\n",
        "pred = rf.predict(X_test_new)\n",
        "mae, mse, rmse = evaluate(y_test, pred)\n",
        "print('MAE  : {:.2f}'.format(mae))\n",
        "print('RMSE : {:.2f}'.format(rmse))\n",
        "results_df.loc['Wrapper:SFS'] = ['Wrapper', 'SFS', mae, rmse, X_train_new.shape[1]]"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE  : 1370.59\n",
            "RMSE : 2106.83\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fFV7thnKg_3"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "z47KuAu4KiDk",
        "outputId": "1b3ee982-ec51-4b37-8ac0-90c2988d4b94"
      },
      "source": [
        "results_df['MAE/Feature'] = results_df.MAE / results_df.Features\n",
        "results_df.sort_values('MAE', ascending=True)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Technique</th>\n",
              "      <th>Method</th>\n",
              "      <th>MAE</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>Features</th>\n",
              "      <th>MAE/Feature</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Filter:Correlated</th>\n",
              "      <td>Filter</td>\n",
              "      <td>Correlated</td>\n",
              "      <td>1360.290502</td>\n",
              "      <td>2080.110845</td>\n",
              "      <td>711</td>\n",
              "      <td>1.91321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Baseline</th>\n",
              "      <td>None</td>\n",
              "      <td>Baseline</td>\n",
              "      <td>1365.874574</td>\n",
              "      <td>2080.472346</td>\n",
              "      <td>828</td>\n",
              "      <td>1.64961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Embedded:Lasso</th>\n",
              "      <td>Embedded</td>\n",
              "      <td>Lasso</td>\n",
              "      <td>1367.010946</td>\n",
              "      <td>2101.341022</td>\n",
              "      <td>218</td>\n",
              "      <td>6.27069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Filter:VarianceThreshold</th>\n",
              "      <td>Filter</td>\n",
              "      <td>VarianceThreshold</td>\n",
              "      <td>1368.460707</td>\n",
              "      <td>2097.571705</td>\n",
              "      <td>825</td>\n",
              "      <td>1.65874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Wrapper:SFS</th>\n",
              "      <td>Wrapper</td>\n",
              "      <td>SFS</td>\n",
              "      <td>1370.588298</td>\n",
              "      <td>2106.831427</td>\n",
              "      <td>80</td>\n",
              "      <td>17.1324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Embedded:RandomForest</th>\n",
              "      <td>Embedded</td>\n",
              "      <td>RandomForest</td>\n",
              "      <td>1372.251590</td>\n",
              "      <td>2080.247835</td>\n",
              "      <td>119</td>\n",
              "      <td>11.5315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Wrapper:RFE</th>\n",
              "      <td>Wrapper</td>\n",
              "      <td>RFE</td>\n",
              "      <td>1399.741243</td>\n",
              "      <td>2108.813025</td>\n",
              "      <td>80</td>\n",
              "      <td>17.4968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Filter:MutualInformation</th>\n",
              "      <td>Filter</td>\n",
              "      <td>Mutual Information</td>\n",
              "      <td>1426.224829</td>\n",
              "      <td>2155.317105</td>\n",
              "      <td>83</td>\n",
              "      <td>17.1834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Filter:F-Score</th>\n",
              "      <td>Filter</td>\n",
              "      <td>F-Score</td>\n",
              "      <td>1438.921143</td>\n",
              "      <td>2165.382789</td>\n",
              "      <td>83</td>\n",
              "      <td>17.3364</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         Technique              Method          MAE  \\\n",
              "Filter:Correlated           Filter          Correlated  1360.290502   \n",
              "Baseline                      None            Baseline  1365.874574   \n",
              "Embedded:Lasso            Embedded               Lasso  1367.010946   \n",
              "Filter:VarianceThreshold    Filter   VarianceThreshold  1368.460707   \n",
              "Wrapper:SFS                Wrapper                 SFS  1370.588298   \n",
              "Embedded:RandomForest     Embedded        RandomForest  1372.251590   \n",
              "Wrapper:RFE                Wrapper                 RFE  1399.741243   \n",
              "Filter:MutualInformation    Filter  Mutual Information  1426.224829   \n",
              "Filter:F-Score              Filter             F-Score  1438.921143   \n",
              "\n",
              "                                 RMSE Features MAE/Feature  \n",
              "Filter:Correlated         2080.110845      711     1.91321  \n",
              "Baseline                  2080.472346      828     1.64961  \n",
              "Embedded:Lasso            2101.341022      218     6.27069  \n",
              "Filter:VarianceThreshold  2097.571705      825     1.65874  \n",
              "Wrapper:SFS               2106.831427       80     17.1324  \n",
              "Embedded:RandomForest     2080.247835      119     11.5315  \n",
              "Wrapper:RFE               2108.813025       80     17.4968  \n",
              "Filter:MutualInformation  2155.317105       83     17.1834  \n",
              "Filter:F-Score            2165.382789       83     17.3364  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uti9nSI4KlNV"
      },
      "source": [
        "# Notes\n",
        "* Three techniques (F.E.W.)\n",
        "  * Filter - Score variables and filter\n",
        "  * Embedded - Look at models that can identify the best features\n",
        "  * Wrapper - Iteratively build or remove features to find best collection\n",
        "* Not PCA (But they both do a similar thing)\n",
        "  * Feature Selection reduces dimensionality without changing features\n",
        "  * PCA transforms (projects) features into a lower dimension space\n",
        "* Sklearn SelectFromModel (SelectKBest, SelectPercentile) can be placed in pipelines\n",
        "* No free lunch (as always)\n",
        "  * My default is building a full model\n",
        "  * Look at variable importance\n",
        "  * Apply RFE or Embedded (with importance)\n",
        "  * I'm skeptical of univariate methods in general\n",
        "    * Greedy\n",
        "    * Interactions can be meaningful\n",
        "    * Rather fight overfitting than underfitting\n",
        "* Mlxtend worth a closer look!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0K91PseNK0iY"
      },
      "source": [
        ""
      ],
      "execution_count": 108,
      "outputs": []
    }
  ]
}